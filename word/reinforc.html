<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
	<meta name="keywords" content="software linguistics, software language engineering, book of knowledge, glossary, academic publications, scientific research, open knowledge, open science"/>
	<title>BibSLEIGH — reinforc stem</title>
	<link href="../stuff/bib.css" rel="stylesheet" type="text/css"/>
	<link href='http://fonts.googleapis.com/css?family=Exo+2:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	<script src="../stuff/jquery.min.js" type="text/javascript"></script>
</head>
<body>
<div class="left">
	<a href="../index.html"><img src="../stuff/bibsleigh.png" alt="BibSLEIGH" title="BibSLEIGH" class="pad"/></a>

	<div class="pad">
		<a href="../index.html"><img src="../stuff/p-corpus.png" alt="BibSLEIGH corpus" title="All papers in the corpus"/></a><br/>
		<a href="../tag/index.html"><img src="../stuff/p-tags.png" alt="BibSLEIGH tags" title="All known tags"/></a><br/>
		<a href="../bundle/index.html"><img src="../stuff/p-bundles.png" alt="BibSLEIGH bundles" title="All selected bundles"/></a><br/>
		<a href="../person/index.html"><img src="../stuff/p-people.png" alt="BibSLEIGH people" title="All contributors"/></a>
	</div>
	<a href="http://creativecommons.org/licenses/by/4.0/" title="CC-BY"><img src="../stuff/cc-by.png" alt="CC-BY"/></a><br/>
	<a href="http://opendatacommons.org/licenses/by/summary/" title="Open Knowledge"><img src="../stuff/open-knowledge.png" alt="Open Knowledge" /></a><br/>
	<a href="http://validator.w3.org/check/referer" title="XHTML 1.0 W3C Rec"><img src="../stuff/xhtml.png" alt="XHTML 1.0 W3C Rec" /></a><br/>
	<a href="http://jigsaw.w3.org/css-validator/check/referer" title="CSS 2.1 W3C CanRec"><img src="../stuff/css.png" alt="CSS 2.1 W3C CanRec" class="pad" /></a><br/>
	<div class="sm">
		<a href="../mailto:vadim@grammarware.net"><img src="../stuff/email.png" alt="email" title="Complain!" /></a>
		<a href="https://twitter.com/intent/tweet?screen_name=grammarware"><img src="../stuff/twitter.png" alt="twitter" title="Mention!" /></a>
	</div>

</div>
<div class="main">
<div class="tbox">
<code>Used together with:</code><hr/><span class="tag"><a href="learn.html">learn</a></span> (206)
<br/><span class="tag"><a href="use.html">use</a></span> (29)
<br/><span class="tag"><a href="base.html">base</a></span> (24)
<br/><span class="tag"><a href="model.html">model</a></span> (24)
<br/><span class="tag"><a href="function.html">function</a></span> (15)
</div>
<h2><span class="ttl">Stem</span> reinforc$ (<a href="../words.html">all stems</a>)</h2>
<h3>205 papers:</h3>
<dl class="toc"><dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2015-AntonelloGM.html">CASE-2015-AntonelloGM</a> <span class="tag"><a href="../tag/detection.html" title="detection">#detection</a></span> <span class="tag"><a href="../tag/fault.html" title="fault">#fault</a></span></dt><dd>Autonomous robotic system for thermographic detection of defects in upper layers of carbon fiber reinforced polymers (<abbr title="Morris Antonello">MA</abbr>, <abbr title="Stefano Ghidoni">SG</abbr>, <abbr title="Emanuele Menegatti">EM</abbr>), pp. 634–639.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2015-LiX.html">CASE-2015-LiX</a> <span class="tag"><a href="../tag/energy.html" title="energy">#energy</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>A multi-grid reinforcement learning method for energy conservation and comfort of HVAC in buildings (<abbr title="Bocheng Li">BL</abbr>, <abbr title="Li Xia">LX</abbr>), pp. 444–449.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/date.png" alt="DATE"/><a href="../DATE-2015-ChenM.html">DATE-2015-ChenM</a> <span class="tag"><a href="../tag/distributed.html" title="distributed">#distributed</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/manycore.html" title="manycore">#manycore</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Distributed reinforcement learning for power limited many-core system performance optimization (<abbr title="Zhuo Chen">ZC</abbr>, <abbr title="Diana Marculescu">DM</abbr>), pp. 1521–1526.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/hci.png" alt="HCI"/><a href="../DHM-HM-2015-KurataniHHKUGH.html">DHM-HM-2015-KurataniHHKUGH</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/comparison.html" title="comparison">#comparison</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Expert vs. Elementary Skill Comparison and Process Analysis in VaRTM-Manufactured Carbon Fiber Reinforced Composites (<abbr title="Yasunari Kuratani">YK</abbr>, <abbr title="Kentaro Hase">KH</abbr>, <abbr title="Takahiro Hosomi">TH</abbr>, <abbr title="Tomoe Kawazu">TK</abbr>, <abbr title="Tadashi Uozumi">TU</abbr>, <abbr title="Akihiko Goto">AG</abbr>, <abbr title="Hiroyuki Hamada">HH</abbr>), pp. 133–142.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-Bou-AmmarTE.html">ICML-2015-Bou-AmmarTE</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/policy.html" title="policy">#policy</a></span> <span class="tag"><a href="../tag/sublinear.html" title="sublinear">#sublinear</a></span></dt><dd>Safe Policy Search for Lifelong Reinforcement Learning with Sublinear Regret (<abbr title="Haitham Bou-Ammar">HBA</abbr>, <abbr title="Rasul Tutunov">RT</abbr>, <abbr title="Eric Eaton">EE</abbr>), pp. 2361–2369.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-JiangKS.html">ICML-2015-JiangKS</a> <span class="tag"><a href="../tag/abstraction.html" title="abstraction">#abstraction</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Abstraction Selection in Model-based Reinforcement Learning (<abbr title="Nan Jiang">NJ</abbr>, <abbr title="Alex Kulesza">AK</abbr>, <abbr title="Satinder Singh">SS</abbr>), pp. 179–188.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-LakshmananOR.html">ICML-2015-LakshmananOR</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Improved Regret Bounds for Undiscounted Continuous Reinforcement Learning (<abbr title="K. Lakshmanan">KL</abbr>, <abbr title="Ronald Ortner">RO</abbr>, <abbr title="Daniil Ryabko">DR</abbr>), pp. 524–532.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2014-HwangLW.html">CASE-2014-HwangLW</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Adaptive reinforcement learning in box-pushing robots (<abbr title="Kao-Shing Hwang">KSH</abbr>, <abbr title="J. L. Ling">JLL</abbr>, <abbr title="Wei-Han Wang">WHW</abbr>), pp. 1182–1187.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/dac.png" alt="DAC"/><a href="../DAC-2014-0001SMAKV.html">DAC-2014-0001SMAKV</a> <span class="tag"><a href="../tag/manycore.html" title="manycore">#manycore</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span></dt><dd>Reinforcement Learning-Based Inter- and Intra-Application Thermal Optimization for Lifetime Improvement of Multicore Systems (<abbr title="Anup Das">AD</abbr>, <abbr title="Rishad A. Shafik">RAS</abbr>, <abbr title="Geoff V. Merrett">GVM</abbr>, <abbr title="Bashir M. Al-Hashimi">BMAH</abbr>, <abbr title="Akash Kumar">AK</abbr>, <abbr title="Bharadwaj Veeravalli">BV</abbr>), p. 6.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/hci.png" alt="HCI"/><a href="../DHM-2014-KikuchiTTGH.html">DHM-2014-KikuchiTTGH</a> <span class="tag"><a href="../tag/information%20management.html" title="information management">#information management</a></span></dt><dd>Biomechanics Investigation of Skillful Technician in Spray-up Fabrication Method — Converting Tacit Knowledge to Explicit Knowledge in the Fiber Reinforced Plastics Molding (<abbr title="Tetsuo Kikuchi">TK</abbr>, <abbr title="Yuichiro Tani">YT</abbr>, <abbr title="Yuka Takai">YT</abbr>, <abbr title="Akihiko Goto">AG</abbr>, <abbr title="Hiroyuki Hamada">HH</abbr>), pp. 24–34.</dd> <div class="pagevis" style="width:10px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-BrunskillL.html">ICML-c2-2014-BrunskillL</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>PAC-inspired Option Discovery in Lifelong Reinforcement Learning (<abbr title="Emma Brunskill">EB</abbr>, <abbr title="Lihong Li">LL</abbr>), pp. 316–324.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-GrandeWH.html">ICML-c2-2014-GrandeWH</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Sample Efficient Reinforcement Learning with Gaussian Processes (<abbr title="Robert C. Grande">RCG</abbr>, <abbr title="Thomas J. Walsh">TJW</abbr>, <abbr title="Jonathan P. How">JPH</abbr>), pp. 1332–1340.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-QinLJ.html">ICML-c2-2014-QinLJ</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span></dt><dd>Sparse Reinforcement Learning via Convex Optimization (<abbr title="Zhiwei Qin">ZQ</abbr>, <abbr title="Weichang Li">WL</abbr>, <abbr title="Firdaus Janoos">FJ</abbr>), pp. 424–432.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2013-0005LSL.html">ICML-c1-2013-0005LSL</a> <span class="tag"><a href="../tag/feature%20model.html" title="feature model">#feature model</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>Online Feature Selection for Model-based Reinforcement Learning (<abbr title="Trung Thanh Nguyen">TTN</abbr>, <abbr title="Zhuoru Li">ZL</abbr>, <abbr title="Tomi Silander">TS</abbr>, <abbr title="Tze-Yun Leong">TYL</abbr>), pp. 498–506.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2013-MaillardNOR.html">ICML-c1-2013-MaillardNOR</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/representation.html" title="representation">#representation</a></span></dt><dd>Optimal Regret Bounds for Selecting the State Representation in Reinforcement Learning (<abbr title="Odalric-Ambrym Maillard">OAM</abbr>, <abbr title="Phuong Nguyen">PN</abbr>, <abbr title="Ronald Ortner">RO</abbr>, <abbr title="Daniil Ryabko">DR</abbr>), pp. 543–551.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-DimitrakakisT.html">ICML-c3-2013-DimitrakakisT</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>ABC Reinforcement Learning (<abbr title="Christos Dimitrakakis">CD</abbr>, <abbr title="Nikolaos Tziortziotis">NT</abbr>), pp. 684–692.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-LattimoreHS.html">ICML-c3-2013-LattimoreHS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>The Sample-Complexity of General Reinforcement Learning (<abbr title="Tor Lattimore">TL</abbr>, <abbr title="Marcus Hutter">MH</abbr>, <abbr title="Peter Sunehag">PS</abbr>), pp. 28–36.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-SilverNBWM.html">ICML-c3-2013-SilverNBWM</a> <span class="tag"><a href="../tag/concurrent.html" title="concurrent">#concurrent</a></span> <span class="tag"><a href="../tag/interactive.html" title="interactive">#interactive</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Concurrent Reinforcement Learning from Customer Interactions (<abbr title="David Silver">DS</abbr>, <abbr title="Leonard Newnham">LN</abbr>, <abbr title="David Barker">DB</abbr>, <abbr title="Suzanne Weller">SW</abbr>, <abbr title="Jason McFall">JM</abbr>), pp. 924–932.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/sigir.png" alt="SIGIR"/><a href="../SIGIR-2013-0001MMNGC.html">SIGIR-2013-0001MMNGC</a> <span class="tag"><a href="../tag/retrieval.html" title="retrieval">#retrieval</a></span></dt><dd>Self reinforcement for important passage retrieval (<abbr title="Ricardo Ribeiro">RR</abbr>, <abbr title="Luís Marujo">LM</abbr>, <abbr title="David Martins de Matos">DMdM</abbr>, <abbr title="João Paulo Neto">JPN</abbr>, <abbr title="Anatole Gershman">AG</abbr>, <abbr title="Jaime G. Carbonell">JGC</abbr>), pp. 845–848.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/re.png" alt="RE"/><a href="../RE-2013-SultanovH.html">RE-2013-SultanovH</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/requirements.html" title="requirements">#requirements</a></span></dt><dd>Application of reinforcement learning to requirements engineering: requirements tracing (<abbr title="Hakim Sultanov">HS</abbr>, <abbr title="Jane Huffman Hayes">JHH</abbr>), pp. 52–61.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/sac.png" alt="SAC"/><a href="../SAC-2013-LinCLG.html">SAC-2013-LinCLG</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/data-driven.html" title="data-driven">#data-driven</a></span> <span class="tag"><a href="../tag/distributed.html" title="distributed">#distributed</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/predict.html" title="predict">#predict</a></span></dt><dd>Distributed dynamic data driven prediction based on reinforcement learning approach (<abbr title="Szu-Yin Lin">SYL</abbr>, <abbr title="Kuo-Ming Chao">KMC</abbr>, <abbr title="Chi-Chun Lo">CCL</abbr>, <abbr title="Nick Godwin">NG</abbr>), pp. 779–784.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/iceis.png" alt="ICEIS"/><a href="../ICEIS-v1-2012-RibeiroFBBDKE.html">ICEIS-v1-2012-RibeiroFBBDKE</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Unified Algorithm to Improve Reinforcement Learning in Dynamic Environments — An Instance-based Approach (<abbr title="Richardson Ribeiro">RR</abbr>, <abbr title="Fábio Favarim">FF</abbr>, <abbr title="Marco A. C. Barbosa">MACB</abbr>, <abbr title="André Pinz Borges">APB</abbr>, <abbr title="Osmar Betazzi Dordal">OBD</abbr>, <abbr title="Alessandro L. Koerich">ALK</abbr>, <abbr title="Fabrício Enembreck">FE</abbr>), pp. 229–238.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/cikm.png" alt="CIKM"/><a href="../CIKM-2012-ChaliHI.html">CIKM-2012-ChaliHI</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Improving the performance of the reinforcement learning model for answering complex questions (<abbr title="Yllias Chali">YC</abbr>, <abbr title="Sadid A. Hasan">SAH</abbr>, <abbr title="Kaisar Imam">KI</abbr>), pp. 2499–2502.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/cikm.png" alt="CIKM"/><a href="../CIKM-2012-JiangSZ.html">CIKM-2012-JiangSZ</a> <span class="tag"><a href="../tag/effectiveness.html" title="effectiveness">#effectiveness</a></span> <span class="tag"><a href="../tag/ranking.html" title="ranking">#ranking</a></span> <span class="tag"><a href="../tag/towards.html" title="towards">#towards</a></span></dt><dd>Towards an effective and unbiased ranking of scientific literature through mutual reinforcement (<abbr title="Xiaorui Jiang">XJ</abbr>, <abbr title="Xiaoping Sun">XS</abbr>, <abbr title="Hai Zhuge">HZ</abbr>), pp. 714–723.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/cikm.png" alt="CIKM"/><a href="../CIKM-2012-YanWLZCL.html">CIKM-2012-YanWLZCL</a> <span class="tag"><a href="../tag/image.html" title="image">#image</a></span> <span class="tag"><a href="../tag/timeline.html" title="timeline">#timeline</a></span> <span class="tag"><a href="../tag/visualisation.html" title="visualisation">#visualisation</a></span></dt><dd>Visualizing timelines: evolutionary summarization via iterative reinforcement between text and image streams (<abbr title="Rui Yan">RY</abbr>, <abbr title="Xiaojun Wan">XW</abbr>, <abbr title="Mirella Lapata">ML</abbr>, <abbr title="Wayne Xin Zhao">WXZ</abbr>, <abbr title="Pu-Jen Cheng">PJC</abbr>, <abbr title="Xiaoming Li">XL</abbr>), pp. 275–284.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-AzarMK.html">ICML-2012-AzarMK</a> <span class="tag"><a href="../tag/complexity.html" title="complexity">#complexity</a></span> <span class="tag"><a href="../tag/generative.html" title="generative">#generative</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/on%20the.html" title="on the">#on the</a></span></dt><dd>On the Sample Complexity of Reinforcement Learning with a Generative Model  (<abbr title="Mohammad Gheshlaghi Azar">MGA</abbr>, <abbr title="Rémi Munos">RM</abbr>, <abbr title="Bert Kappen">BK</abbr>), p. 222.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-Painter-WakefieldP.html">ICML-2012-Painter-WakefieldP</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Greedy Algorithms for Sparse Reinforcement Learning (<abbr title="Christopher Painter-Wakefield">CPW</abbr>, <abbr title="Ronald Parr">RP</abbr>), p. 114.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-PiresS.html">ICML-2012-PiresS</a> <span class="tag"><a href="../tag/estimation.html" title="estimation">#estimation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span> <span class="tag"><a href="../tag/statistics.html" title="statistics">#statistics</a></span></dt><dd>Statistical linear estimation with penalized estimators: an application to reinforcement learning (<abbr title="Bernardo Avila Pires">BAP</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>), p. 228.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-RossB.html">ICML-2012-RossB</a> <span class="tag"><a href="../tag/identification.html" title="identification">#identification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Agnostic System Identification for Model-Based Reinforcement Learning (<abbr title="Stéphane Ross">SR</abbr>, <abbr title="Drew Bagnell">DB</abbr>), p. 247.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-WangWHL.html">ICML-2012-WangWHL</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/monte%20carlo.html" title="monte carlo">#monte carlo</a></span></dt><dd>Monte Carlo Bayesian Reinforcement Learning (<abbr title="Yi Wang">YW</abbr>, <abbr title="Kok Sung Won">KSW</abbr>, <abbr title="David Hsu">DH</abbr>, <abbr title="Wee Sun Lee">WSL</abbr>), p. 105.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-XieHS.html">ICML-2012-XieHS</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/automation.html" title="automation">#automation</a></span> <span class="tag"><a href="../tag/generative.html" title="generative">#generative</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting (<abbr title="Ning Xie">NX</abbr>, <abbr title="Hirotaka Hachiya">HH</abbr>, <abbr title="Masashi Sugiyama">MS</abbr>), p. 139.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/kmis.png" alt="KMIS"/><a href="../KMIS-2012-HamadaAS.html">KMIS-2012-HamadaAS</a> <span class="tag"><a href="../tag/generative.html" title="generative">#generative</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>A Generation Method of Reference Operation using Reinforcement Learning on Project Manager Skill-up Simulator (<abbr title="Keiichi Hamada">KH</abbr>, <abbr title="Masanori Akiyoshi">MA</abbr>, <abbr title="Masaki Samejima">MS</abbr>), pp. 15–20.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/dac.png" alt="DAC"/><a href="../DAC-2011-WangXAP.html">DAC-2011-WangXAP</a> <span class="tag"><a href="../tag/classification.html" title="classification">#classification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/policy.html" title="policy">#policy</a></span> <span class="tag"><a href="../tag/power%20management.html" title="power management">#power management</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Deriving a near-optimal power management policy using model-free reinforcement learning and Bayesian classification (<abbr title="Yanzhi Wang">YW</abbr>, <abbr title="Qing Xie">QX</abbr>, <abbr title="Ahmed C. Ammari">ACA</abbr>, <abbr title="Massoud Pedram">MP</abbr>), pp. 41–46.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2010-DoroodgarN.html">CASE-2010-DoroodgarN</a> <span class="tag"><a href="../tag/architecture.html" title="architecture">#architecture</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A hierarchical reinforcement learning based control architecture for semi-autonomous rescue robots in cluttered environments (<abbr title="Barzin Doroodgar">BD</abbr>, <abbr title="Goldie Nejat">GN</abbr>), pp. 948–953.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/date.png" alt="DATE"/><a href="../DATE-2010-YeHL.html">DATE-2010-YeHL</a> <span class="tag"><a href="../tag/fault.html" title="fault">#fault</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Diagnosis of multiple arbitrary faults with mask and reinforcement effect (<abbr title="Jing Ye">JY</abbr>, <abbr title="Yu Hu">YH</abbr>, <abbr title="Xiaowei Li">XL</abbr>), pp. 885–890.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/chi.png" alt="CHI"/><a href="../CHI-2010-Villamarin-SalomonB.html">CHI-2010-Villamarin-SalomonB</a> <span class="tag"><a href="../tag/behaviour.html" title="behaviour">#behaviour</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Using reinforcement to strengthen users’ secure behaviors (<abbr title="Ricardo Villamarín-Salomón">RVS</abbr>, <abbr title="José Carlos Brustoloni">JCB</abbr>), pp. 363–372.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-LazaricG.html">ICML-2010-LazaricG</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Bayesian Multi-Task Reinforcement Learning (<abbr title="Alessandro Lazaric">AL</abbr>, <abbr title="Mohammad Ghavamzadeh">MG</abbr>), pp. 599–606.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-LizotteBM.html">ICML-2010-LizotteBM</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/random.html" title="random">#random</a></span></dt><dd>Efficient Reinforcement Learning with Multiple Reward Functions for Randomized Controlled Trial Analysis (<abbr title="Daniel J. Lizotte">DJL</abbr>, <abbr title="Michael H. Bowling">MHB</abbr>, <abbr title="Susan A. Murphy">SAM</abbr>), pp. 695–702.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-Mahmud.html">ICML-2010-Mahmud</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Constructing States for Reinforcement Learning (<abbr title="M. M. Hassan Mahmud">MMHM</abbr>), pp. 727–734.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-MorimuraSKHT.html">ICML-2010-MorimuraSKHT</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Nonparametric Return Distribution Approximation for Reinforcement Learning (<abbr title="Tetsuro Morimura">TM</abbr>, <abbr title="Masashi Sugiyama">MS</abbr>, <abbr title="Hisashi Kashima">HK</abbr>, <abbr title="Hirotaka Hachiya">HH</abbr>, <abbr title="Toshiyuki Tanaka">TT</abbr>), pp. 799–806.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-SzitaS.html">ICML-2010-SzitaS</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/complexity.html" title="complexity">#complexity</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Model-based reinforcement learning with nearly tight exploration complexity bounds (<abbr title="Istvan Szita">IS</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>), pp. 1031–1038.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icpr.png" alt="ICPR"/><a href="../ICPR-2010-CohenP.html">ICPR-2010-CohenP</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/robust.html" title="robust">#robust</a></span></dt><dd>Reinforcement Learning for Robust and Efficient Real-World Tracking (<abbr title="Andre Cohen">AC</abbr>, <abbr title="Vladimir Pavlovic">VP</abbr>), pp. 2989–2992.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/seke.png" alt="SEKE"/><a href="../SEKE-2010-JuniorLAMW.html">SEKE-2010-JuniorLAMW</a> <span class="tag"><a href="../tag/impact%20analysis.html" title="impact analysis">#impact analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Impact Analysis Model for Brasília Area Control Center using Multi-agent System with Reinforcement Learning (<abbr title="Antonio Carlos de Arruda Junior">ACdAJ</abbr>, <abbr title="Alessandro Ferreira Leite">AFL</abbr>, <abbr title="Cícero Roberto Ferreira de Almeida">CRFdA</abbr>, <abbr title="Alba Cristina Magalhaes Alves de Melo">ACMAdM</abbr>, <abbr title="Li Weigang">LW</abbr>), pp. 499–502.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/hpdc.png" alt="HPDC"/><a href="../HPDC-2009-Reeuwijk.html">HPDC-2009-Reeuwijk</a> <span class="tag"><a href="../tag/data%20flow.html" title="data flow">#data flow</a></span> <span class="tag"><a href="../tag/framework.html" title="framework">#framework</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/named.html" title="named">#named</a></span> <span class="tag"><a href="../tag/peer-to-peer.html" title="peer-to-peer">#peer-to-peer</a></span> <span class="tag"><a href="../tag/self.html" title="self">#self</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Maestro: a self-organizing peer-to-peer dataflow framework using reinforcement learning (<abbr title="C. van Reeuwijk">CvR</abbr>), pp. 187–196.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-DiukLL.html">ICML-2009-DiukLL</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/feature%20model.html" title="feature model">#feature model</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>The adaptive k-meteorologists problem and its application to structure learning and feature selection in reinforcement learning (<abbr title="Carlos Diuk">CD</abbr>, <abbr title="Lihong Li">LL</abbr>, <abbr title="Bethany R. Leffler">BRL</abbr>), pp. 249–256.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-Niv.html">ICML-2009-Niv</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/tutorial.html" title="tutorial">#tutorial</a></span></dt><dd>Tutorial summary: The neuroscience of reinforcement learning (<abbr title="Yael Niv">YN</abbr>), p. 16.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-Simsek.html">ICML-2009-Simsek</a> <span class="tag"><a href="../tag/abstraction.html" title="abstraction">#abstraction</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Workshop summary: Abstraction in reinforcement learning (<abbr title="Özgür Simsek">ÖS</abbr>), p. 10.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-TaylorP.html">ICML-2009-TaylorP</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/kernel.html" title="kernel">#kernel</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Kernelized value function approximation for reinforcement learning (<abbr title="Gavin Taylor">GT</abbr>, <abbr title="Ronald Parr">RP</abbr>), pp. 1017–1024.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-VlassisT.html">ICML-2009-VlassisT</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Model-free reinforcement learning as mixture learning (<abbr title="Nikos Vlassis">NV</abbr>, <abbr title="Marc Toussaint">MT</abbr>), pp. 1081–1088.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-WingateDLTF.html">ICML-2009-WingateDLTF</a> <span class="tag"><a href="../tag/contest.html" title="contest">#contest</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Workshop summary: Results of the 2009 reinforcement learning competition (<abbr title="David Wingate">DW</abbr>, <abbr title="Carlos Diuk">CD</abbr>, <abbr title="Lihong Li">LL</abbr>, <abbr title="Matthew Taylor">MT</abbr>, <abbr title="Jordan Frank">JF</abbr>), p. 6.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/kmis.png" alt="KMIS"/><a href="../KMIS-2009-ZyglarskiB.html">KMIS-2009-ZyglarskiB</a> <span class="tag"><a href="../tag/documentation.html" title="documentation">#documentation</a></span> <span class="tag"><a href="../tag/keyword.html" title="keyword">#keyword</a></span> <span class="tag"><a href="../tag/network.html" title="network">#network</a></span></dt><dd>Scientific Documents Management System — Application of Kohonens Neural Networks with Reinforcement in Keywords Extraction (<abbr title="Blazej Zyglarski">BZ</abbr>, <abbr title="Piotr Bala">PB</abbr>), pp. 55–62.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2008-StabelliniZ.html">CASE-2008-StabelliniZ</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/network.html" title="network">#network</a></span> <span class="tag"><a href="../tag/self.html" title="self">#self</a></span></dt><dd>Interference aware self-organization for wireless sensor networks: A reinforcement learning approach (<abbr title="Luca Stabellini">LS</abbr>, <abbr title="Jens Zander">JZ</abbr>), pp. 560–565.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-DiukCL.html">ICML-2008-DiukCL</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/object-oriented.html" title="object-oriented">#object-oriented</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/representation.html" title="representation">#representation</a></span></dt><dd>An object-oriented representation for efficient reinforcement learning (<abbr title="Carlos Diuk">CD</abbr>, <abbr title="Andre Cohen">AC</abbr>, <abbr title="Michael L. Littman">MLL</abbr>), pp. 240–247.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-DoshiPR.html">ICML-2008-DoshiPR</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Reinforcement learning with limited reinforcement: using Bayes risk for active learning in POMDPs (<abbr title="Finale Doshi">FD</abbr>, <abbr title="Joelle Pineau">JP</abbr>, <abbr title="Nicholas Roy">NR</abbr>), pp. 256–263.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-EpshteynVD.html">ICML-2008-EpshteynVD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Active reinforcement learning (<abbr title="Arkady Epshteyn">AE</abbr>, <abbr title="Adam Vogel">AV</abbr>, <abbr title="Gerald DeJong">GD</abbr>), pp. 296–303.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-FrankMP.html">ICML-2008-FrankMP</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement learning in the presence of rare events (<abbr title="Jordan Frank">JF</abbr>, <abbr title="Shie Mannor">SM</abbr>, <abbr title="Doina Precup">DP</abbr>), pp. 336–343.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-LazaricRB.html">ICML-2008-LazaricRB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Transfer of samples in batch reinforcement learning (<abbr title="Alessandro Lazaric">AL</abbr>, <abbr title="Marcello Restelli">MR</abbr>, <abbr title="Andrea Bonarini">AB</abbr>), pp. 544–551.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-MeloMR.html">ICML-2008-MeloMR</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>An analysis of reinforcement learning with function approximation (<abbr title="Francisco S. Melo">FSM</abbr>, <abbr title="Sean P. Meyn">SPM</abbr>, <abbr title="M. Isabel Ribeiro">MIR</abbr>), pp. 664–671.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-ParrLTPL.html">ICML-2008-ParrLTPL</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/feature%20model.html" title="feature model">#feature model</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning (<abbr title="Ronald Parr">RP</abbr>, <abbr title="Lihong Li">LL</abbr>, <abbr title="Gavin Taylor">GT</abbr>, <abbr title="Christopher Painter-Wakefield">CPW</abbr>, <abbr title="Michael L. Littman">MLL</abbr>), pp. 752–759.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-ReisingerSM.html">ICML-2008-ReisingerSM</a> <span class="tag"><a href="../tag/kernel.html" title="kernel">#kernel</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>Online kernel selection for Bayesian reinforcement learning (<abbr title="Joseph Reisinger">JR</abbr>, <abbr title="Peter Stone">PS</abbr>, <abbr title="Risto Miikkulainen">RM</abbr>), pp. 816–823.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-SakumaKW.html">ICML-2008-SakumaKW</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/privacy.html" title="privacy">#privacy</a></span></dt><dd>Privacy-preserving reinforcement learning (<abbr title="Jun Sakuma">JS</abbr>, <abbr title="Shigenobu Kobayashi">SK</abbr>, <abbr title="Rebecca N. Wright">RNW</abbr>), pp. 864–871.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/sigir.png" alt="SIGIR"/><a href="../SIGIR-2008-WeiLLH.html">SIGIR-2008-WeiLLH</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/query.html" title="query">#query</a></span></dt><dd>Query-sensitive mutual reinforcement chain and its application in query-oriented multi-document summarization (<abbr title="Furu Wei">FW</abbr>, <abbr title="Wenjie Li">WL</abbr>, <abbr title="Qin Lu">QL</abbr>, <abbr title="Yanxiang He">YH</abbr>), pp. 283–290.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/oopsla.png" alt="OOPSLA"/><a href="../OOPSLA-2008-SimpkinsBIM.html">OOPSLA-2008-SimpkinsBIM</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/programming%20language.html" title="programming language">#programming language</a></span> <span class="tag"><a href="../tag/towards.html" title="towards">#towards</a></span></dt><dd>Towards adaptive programming: integrating reinforcement learning into a programming language (<abbr title="Christopher Simpkins">CS</abbr>, <abbr title="Sooraj Bhat">SB</abbr>, <abbr title="Charles Lee Isbell Jr.">CLIJ</abbr>, <abbr title="Michael Mateas">MM</abbr>), pp. 603–614.</dd> <div class="pagevis" style="width:11px"></div>
<dt><img src="../stuff/re.png" alt="RE"/><a href="../RE-2008-SmithG.html">RE-2008-SmithG</a> <span class="tag"><a href="../tag/requirements.html" title="requirements">#requirements</a></span></dt><dd>Gameplay to Introduce and Reinforce Requirements Engineering Practices (<abbr title="Renel Smith">RS</abbr>, <abbr title="Orlena Gotel">OG</abbr>), pp. 95–104.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/sac.png" alt="SAC"/><a href="../SAC-2008-TierneyJ.html">SAC-2008-TierneyJ</a> <span class="tag"><a href="../tag/ontology.html" title="ontology">#ontology</a></span> <span class="tag"><a href="../tag/semantics.html" title="semantics">#semantics</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>C-SAW---contextual semantic alignment of ontologies: using negative semantic reinforcement (<abbr title="Brendan Tierney">BT</abbr>, <abbr title="Mike Jackson">MJ</abbr>), pp. 2346–2347.</dd> <div class="pagevis" style="width:1px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-PetersS.html">ICML-2007-PetersS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement learning by reward-weighted regression for operational space control (<abbr title="Jan Peters">JP</abbr>, <abbr title="Stefan Schaal">SS</abbr>), pp. 745–750.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-PhuaF.html">ICML-2007-PhuaF</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span></dt><dd>Tracking value function dynamics to improve reinforcement learning with piecewise linear function approximation (<abbr title="Chee Wee Phua">CWP</abbr>, <abbr title="Robert Fitch">RF</abbr>), pp. 751–758.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-TaylorS.html">ICML-2007-TaylorS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Cross-domain transfer for reinforcement learning (<abbr title="Matthew E. Taylor">MET</abbr>, <abbr title="Peter Stone">PS</abbr>), pp. 879–886.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-WilsonFRT.html">ICML-2007-WilsonFRT</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-task reinforcement learning: a hierarchical Bayesian approach (<abbr title="Aaron Wilson">AW</abbr>, <abbr title="Alan Fern">AF</abbr>, <abbr title="Soumya Ray">SR</abbr>, <abbr title="Prasad Tadepalli">PT</abbr>), pp. 1015–1022.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-ZhangAV.html">ICML-2007-ZhangAV</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/random.html" title="random">#random</a></span></dt><dd>Conditional random fields for multi-agent reinforcement learning (<abbr title="Xinhua Zhang">XZ</abbr>, <abbr title="Douglas Aberdeen">DA</abbr>, <abbr title="S. V. N. Vishwanathan">SVNV</abbr>), pp. 1143–1150.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/recsys.png" alt="RecSys"/><a href="../RecSys-2007-TaghipourKG.html">RecSys-2007-TaghipourKG</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/recommendation.html" title="recommendation">#recommendation</a></span> <span class="tag"><a href="../tag/web.html" title="web">#web</a></span></dt><dd>Usage-based web recommendations: a reinforcement learning approach (<abbr title="Nima Taghipour">NT</abbr>, <abbr title="Ahmad A. Kardan">AAK</abbr>, <abbr title="Saeed Shiry Ghidary">SSG</abbr>), pp. 113–120.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-AbbeelQN.html">ICML-2006-AbbeelQN</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Using inaccurate models in reinforcement learning (<abbr title="Pieter Abbeel">PA</abbr>, <abbr title="Morgan Quigley">MQ</abbr>, <abbr title="Andrew Y. Ng">AYN</abbr>), pp. 1–8.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-DegrisSW.html">ICML-2006-DegrisSW</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/markov.html" title="markov">#markov</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Learning the structure of Factored Markov Decision Processes in reinforcement learning problems (<abbr title="Thomas Degris">TD</abbr>, <abbr title="Olivier Sigaud">OS</abbr>, <abbr title="Pierre-Henri Wuillemin">PHW</abbr>), pp. 257–264.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-EpshteynD.html">ICML-2006-EpshteynD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Qualitative reinforcement learning (<abbr title="Arkady Epshteyn">AE</abbr>, <abbr title="Gerald DeJong">GD</abbr>), pp. 305–312.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-KellerMP.html">ICML-2006-KellerMP</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/automation.html" title="automation">#automation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/programming.html" title="programming">#programming</a></span></dt><dd>Automatic basis function construction for approximate dynamic programming and reinforcement learning (<abbr title="Philipp W. Keller">PWK</abbr>, <abbr title="Shie Mannor">SM</abbr>, <abbr title="Doina Precup">DP</abbr>), pp. 449–456.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-KonidarisB.html">ICML-2006-KonidarisB</a> <span class="tag"><a href="../tag/information%20management.html" title="information management">#information management</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Autonomous shaping: knowledge transfer in reinforcement learning (<abbr title="George Konidaris">GK</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>), pp. 489–496.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-NevmyvakaFK.html">ICML-2006-NevmyvakaFK</a> <span class="tag"><a href="../tag/execution.html" title="execution">#execution</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement learning for optimized trade execution (<abbr title="Yuriy Nevmyvaka">YN</abbr>, <abbr title="Yi Feng">YF</abbr>, <abbr title="Michael Kearns">MK</abbr>), pp. 673–680.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-PoupartVHR.html">ICML-2006-PoupartVHR</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>An analytic solution to discrete Bayesian reinforcement learning (<abbr title="Pascal Poupart">PP</abbr>, <abbr title="Nikos A. Vlassis">NAV</abbr>, <abbr title="Jesse Hoey">JH</abbr>, <abbr title="Kevin Regan">KR</abbr>), pp. 697–704.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-StrehlLWLL.html">ICML-2006-StrehlLWLL</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>PAC model-free reinforcement learning (<abbr title="Alexander L. Strehl">ALS</abbr>, <abbr title="Lihong Li">LL</abbr>, <abbr title="Eric Wiewiora">EW</abbr>, <abbr title="John Langford">JL</abbr>, <abbr title="Michael L. Littman">MLL</abbr>), pp. 881–888.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icpr.png" alt="ICPR"/><a href="../ICPR-v4-2006-ZhengLL.html">ICPR-v4-2006-ZhengLL</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/network.html" title="network">#network</a></span></dt><dd>Control Double Inverted Pendulum by Reinforcement Learning with Double CMAC Network (<abbr title="Yu Zheng">YZ</abbr>, <abbr title="Siwei Luo">SL</abbr>, <abbr title="Ziang Lv">ZL</abbr>), pp. 639–642.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/fates.png" alt="FATES"/><a href="../FATES-RV-2006-VeanesRC.html">FATES-RV-2006-VeanesRC</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span> <span class="tag"><a href="../tag/testing.html" title="testing">#testing</a></span></dt><dd>Online Testing with Reinforcement Learning (<abbr title="Margus Veanes">MV</abbr>, <abbr title="Pritam Roy">PR</abbr>, <abbr title="Colin Campbell">CC</abbr>), pp. 240–253.</dd> <div class="pagevis" style="width:13px"></div>
<dt><img src="../stuff/iceis.png" alt="ICEIS"/><a href="../ICEIS-v2-2005-LokugeA.html">ICEIS-v2-2005-LokugeA</a> <span class="tag"><a href="../tag/hybrid.html" title="hybrid">#hybrid</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Handling Multiple Events in Hybrid BDI Agents with Reinforcement Learning: A Container Application (<abbr title="Prasanna Lokuge">PL</abbr>, <abbr title="Damminda Alahakoon">DA</abbr>), pp. 83–90.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-AbbeelN.html">ICML-2005-AbbeelN</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Exploration and apprenticeship learning in reinforcement learning (<abbr title="Pieter Abbeel">PA</abbr>, <abbr title="Andrew Y. Ng">AYN</abbr>), pp. 1–8.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-EngelMM.html">ICML-2005-EngelMM</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Reinforcement learning with Gaussian processes (<abbr title="Yaakov Engel">YE</abbr>, <abbr title="Shie Mannor">SM</abbr>, <abbr title="Ron Meir">RM</abbr>), pp. 201–208.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-GroisW.html">ICML-2005-GroisW</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/comprehension.html" title="comprehension">#comprehension</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Learning strategies for story comprehension: a reinforcement learning approach (<abbr title="Eugene Grois">EG</abbr>, <abbr title="David C. Wilkins">DCW</abbr>), pp. 257–264.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-LangfordZ.html">ICML-2005-LangfordZ</a> <span class="tag"><a href="../tag/classification.html" title="classification">#classification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Relating reinforcement learning performance to classification performance (<abbr title="John Langford">JL</abbr>, <abbr title="Bianca Zadrozny">BZ</abbr>), pp. 473–480.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-Mahadevan.html">ICML-2005-Mahadevan</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Proto-value functions: developmental reinforcement learning (<abbr title="Sridhar Mahadevan">SM</abbr>), pp. 553–560.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-MichelsSN.html">ICML-2005-MichelsSN</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>High speed obstacle avoidance using monocular vision and reinforcement learning (<abbr title="Jeff Michels">JM</abbr>, <abbr title="Ashutosh Saxena">AS</abbr>, <abbr title="Andrew Y. Ng">AYN</abbr>), pp. 593–600.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-NatarajanT.html">ICML-2005-NatarajanT</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Dynamic preferences in multi-criteria reinforcement learning (<abbr title="Sriraam Natarajan">SN</abbr>, <abbr title="Prasad Tadepalli">PT</abbr>), pp. 601–608.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2005-SimsekWB.html">ICML-2005-SimsekWB</a> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/graph.html" title="graph">#graph</a></span> <span class="tag"><a href="../tag/identification.html" title="identification">#identification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Identifying useful subgoals in reinforcement learning by local graph partitioning (<abbr title="Özgür Simsek">ÖS</abbr>, <abbr title="Alicia P. Wolfe">APW</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>), pp. 816–823.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/mldm.png" alt="MLDM"/><a href="../MLDM-2005-KuhnertK.html">MLDM-2005-KuhnertK</a> <span class="tag"><a href="../tag/feedback.html" title="feedback">#feedback</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Autonomous Vehicle Steering Based on Evaluative Feedback by Reinforcement Learning (<abbr title="Klaus-Dieter Kuhnert">KDK</abbr>, <abbr title="Michael Krödel">MK</abbr>), pp. 405–414.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/mldm.png" alt="MLDM"/><a href="../MLDM-2005-SilvaJNP.html">MLDM-2005-SilvaJNP</a> <span class="tag"><a href="../tag/geometry.html" title="geometry">#geometry</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/metric.html" title="metric">#metric</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Diagnosis of Lung Nodule Using Reinforcement Learning and Geometric Measures (<abbr title="Aristófanes Corrêa Silva">ACS</abbr>, <abbr title="Valdeci Ribeiro da Silva Jr.">VRdSJ</abbr>, <abbr title="Areolino de Almeida Neto">AdAN</abbr>, <abbr title="Anselmo Cardoso de Paiva">ACdP</abbr>), pp. 295–304.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/sac.png" alt="SAC"/><a href="../SAC-2005-KatayamaKN.html">SAC-2005-KatayamaKN</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Reinforcement learning agents with primary knowledge designed by analytic hierarchy process (<abbr title="Kengo Katayama">KK</abbr>, <abbr title="Takahiro Koshiishi">TK</abbr>, <abbr title="Hiroyuki Narihisa">HN</abbr>), pp. 14–21.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/sac.png" alt="SAC"/><a href="../SAC-2005-TebriBC.html">SAC-2005-TebriBC</a> <span class="tag"><a href="../tag/incremental.html" title="incremental">#incremental</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Incremental profile learning based on a reinforcement method (<abbr title="Hamid Tebri">HT</abbr>, <abbr title="Mohand Boughanem">MB</abbr>, <abbr title="Claude Chrisment">CC</abbr>), pp. 1096–1101.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-MannorMHK.html">ICML-2004-MannorMHK</a> <span class="tag"><a href="../tag/abstraction.html" title="abstraction">#abstraction</a></span> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Dynamic abstraction in reinforcement learning via clustering (<abbr title="Shie Mannor">SM</abbr>, <abbr title="Ishai Menache">IM</abbr>, <abbr title="Amit Hoze">AH</abbr>, <abbr title="Uri Klein">UK</abbr>).</dd> 
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-MerkeS.html">ICML-2004-MerkeS</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/convergence.html" title="convergence">#convergence</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span></dt><dd>Convergence of synchronous reinforcement learning with linear function approximation (<abbr title="Artur Merke">AM</abbr>, <abbr title="Ralf Schoknecht">RS</abbr>).</dd> 
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-MoralesS.html">ICML-2004-MoralesS</a> <span class="tag"><a href="../tag/behaviour.html" title="behaviour">#behaviour</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Learning to fly by combining reinforcement learning with behavioural cloning (<abbr title="Eduardo F. Morales">EFM</abbr>, <abbr title="Claude Sammut">CS</abbr>).</dd> 
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-PieterN.html">ICML-2004-PieterN</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Apprenticeship learning via inverse reinforcement learning (<abbr title="Pieter Abbeel">PA</abbr>, <abbr title="Andrew Y. Ng">AYN</abbr>).</dd> 
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-RudarySP.html">ICML-2004-RudarySP</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/constraints.html" title="constraints">#constraints</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/reasoning.html" title="reasoning">#reasoning</a></span></dt><dd>Adaptive cognitive orthotics: combining reinforcement learning and constraint-based temporal reasoning (<abbr title="Matthew R. Rudary">MRR</abbr>, <abbr title="Satinder P. Singh">SPS</abbr>, <abbr title="Martha E. Pollack">MEP</abbr>).</dd> 
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2004-SimsekB.html">ICML-2004-SimsekB</a> <span class="tag"><a href="../tag/abstraction.html" title="abstraction">#abstraction</a></span> <span class="tag"><a href="../tag/identification.html" title="identification">#identification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Using relative novelty to identify useful temporal abstractions in reinforcement learning (<abbr title="Özgür Simsek">ÖS</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>).</dd> 
<dt><img src="../stuff/icpr.png" alt="ICPR"/><a href="../ICPR-v2-2004-LiuS.html">ICPR-v2-2004-LiuS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning-Based Feature Learning for Object Tracking (<abbr title="Fang Liu">FL</abbr>, <abbr title="Jianbo Su">JS</abbr>), pp. 748–751.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-DriessensR.html">ICML-2003-DriessensR</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/relational.html" title="relational">#relational</a></span></dt><dd>Relational Instance Based Regression for Relational Reinforcement Learning (<abbr title="Kurt Driessens">KD</abbr>, <abbr title="Jan Ramon">JR</abbr>), pp. 123–130.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-Even-DarMM.html">ICML-2003-Even-DarMM</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Action Elimination and Stopping Conditions for Reinforcement Learning (<abbr title="Eyal Even-Dar">EED</abbr>, <abbr title="Shie Mannor">SM</abbr>, <abbr title="Yishay Mansour">YM</abbr>), pp. 162–169.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-LagoudakisP.html">ICML-2003-LagoudakisP</a> <span class="tag"><a href="../tag/classification.html" title="classification">#classification</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning as Classification: Leveraging Modern Classifiers (<abbr title="Michail G. Lagoudakis">MGL</abbr>, <abbr title="Ronald Parr">RP</abbr>), pp. 424–431.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-LaudD.html">ICML-2003-LaudD</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>The Influence of Reward on the Speed of Reinforcement Learning: An Analysis of Shaping (<abbr title="Adam Laud">AL</abbr>, <abbr title="Gerald DeJong">GD</abbr>), pp. 440–447.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-RussellZ.html">ICML-2003-RussellZ</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Q-Decomposition for Reinforcement Learning Agents (<abbr title="Stuart J. Russell">SJR</abbr>, <abbr title="Andrew Zimdars">AZ</abbr>), pp. 656–663.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-WangD.html">ICML-2003-WangD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/policy.html" title="policy">#policy</a></span></dt><dd>Model-based Policy Gradient Reinforcement Learning (<abbr title="Xin Wang">XW</abbr>, <abbr title="Thomas G. Dietterich">TGD</abbr>), pp. 776–783.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2003-WiewioraCE.html">ICML-2003-WiewioraCE</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Principled Methods for Advising Reinforcement Learning Agents (<abbr title="Eric Wiewiora">EW</abbr>, <abbr title="Garrison W. Cottrell">GWC</abbr>, <abbr title="Charles Elkan">CE</abbr>), pp. 792–799.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/sigir.png" alt="SIGIR"/><a href="../SIGIR-2003-WangZCLTM.html">SIGIR-2003-WangZCLTM</a> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/named.html" title="named">#named</a></span></dt><dd>ReCoM: reinforcement clustering of multi-type interrelated data objects (<abbr title="Jidong Wang">JW</abbr>, <abbr title="Hua-Jun Zeng">HJZ</abbr>, <abbr title="Zheng Chen">ZC</abbr>, <abbr title="Hongjun Lu">HL</abbr>, <abbr title="Li Tao">LT</abbr>, <abbr title="Wei-Ying Ma">WYM</abbr>), pp. 274–281.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-DietterichBMS.html">ICML-2002-DietterichBMS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span> <span class="tag"><a href="../tag/refinement.html" title="refinement">#refinement</a></span></dt><dd>Action Refinement in Reinforcement Learning by Probability Smoothing (<abbr title="Thomas G. Dietterich">TGD</abbr>, <abbr title="Dídac Busquets">DB</abbr>, <abbr title="Ramon López de Mántaras">RLdM</abbr>, <abbr title="Carles Sierra">CS</abbr>), pp. 107–114.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-DriessensD.html">ICML-2002-DriessensD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/relational.html" title="relational">#relational</a></span></dt><dd>Integrating Experimentation and Guidance in Relational Reinforcement Learning (<abbr title="Kurt Driessens">KD</abbr>, <abbr title="Saso Dzeroski">SD</abbr>), pp. 115–122.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-GhavamzadehM.html">ICML-2002-GhavamzadehM</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Hierarchically Optimal Average Reward Reinforcement Learning (<abbr title="Mohammad Ghavamzadeh">MG</abbr>, <abbr title="Sridhar Mahadevan">SM</abbr>), pp. 195–202.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-GuestrinLP.html">ICML-2002-GuestrinLP</a> <span class="tag"><a href="../tag/coordination.html" title="coordination">#coordination</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Coordinated Reinforcement Learning (<abbr title="Carlos Guestrin">CG</abbr>, <abbr title="Michail G. Lagoudakis">MGL</abbr>, <abbr title="Ronald Parr">RP</abbr>), pp. 227–234.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-GuestrinPS.html">ICML-2002-GuestrinPS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Algorithm-Directed Exploration for Model-Based Reinforcement Learning in Factored MDPs (<abbr title="Carlos Guestrin">CG</abbr>, <abbr title="Relu Patrascu">RP</abbr>, <abbr title="Dale Schuurmans">DS</abbr>), pp. 235–242.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-Hengst.html">ICML-2002-Hengst</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Discovering Hierarchy in Reinforcement Learning with HEXQ (<abbr title="Bernhard Hengst">BH</abbr>), pp. 243–250.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-KakadeL.html">ICML-2002-KakadeL</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Approximately Optimal Approximate Reinforcement Learning (<abbr title="Sham Kakade">SK</abbr>, <abbr title="John Langford">JL</abbr>), pp. 267–274.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-LaudD.html">ICML-2002-LaudD</a> <span class="tag"><a href="../tag/behaviour.html" title="behaviour">#behaviour</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning and Shaping: Encouraging Intended Behaviors (<abbr title="Adam Laud">AL</abbr>, <abbr title="Gerald DeJong">GD</abbr>), pp. 355–362.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-MerkeS.html">ICML-2002-MerkeS</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/convergence.html" title="convergence">#convergence</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Necessary Condition of Convergence for Reinforcement Learning with Function Approximation (<abbr title="Artur Merke">AM</abbr>, <abbr title="Ralf Schoknecht">RS</abbr>), pp. 411–418.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-OLZ.html">ICML-2002-OLZ</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Stock Trading System Using Reinforcement Learning with Cooperative Agents (<abbr title="Jangmin O">JO</abbr>, <abbr title="Jae Won Lee">JWL</abbr>, <abbr title="Byoung-Tak Zhang">BTZ</abbr>), pp. 451–458.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-PickettB.html">ICML-2002-PickettB</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/named.html" title="named">#named</a></span></dt><dd>PolicyBlocks: An Algorithm for Creating Useful Macro-Actions in Reinforcement Learning (<abbr title="Marc Pickett">MP</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>), pp. 506–513.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-Ryan.html">ICML-2002-Ryan</a> <span class="tag"><a href="../tag/automation.html" title="automation">#automation</a></span> <span class="tag"><a href="../tag/behaviour.html" title="behaviour">#behaviour</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Using Abstract Models of Behaviours to Automatically Generate Reinforcement Learning Hierarchies (<abbr title="Malcolm R. K. Ryan">MRKR</abbr>), pp. 522–529.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2002-SeriT.html">ICML-2002-SeriT</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Model-based Hierarchical Average-reward Reinforcement Learning (<abbr title="Sandeep Seri">SS</abbr>, <abbr title="Prasad Tadepalli">PT</abbr>), pp. 562–569.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/sigir.png" alt="SIGIR"/><a href="../SIGIR-2002-Zha.html">SIGIR-2002-Zha</a> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Generic summarization and keyphrase extraction using mutual reinforcement principle and sentence clustering (<abbr title="Hongyuan Zha">HZ</abbr>), pp. 113–120.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-Geibel.html">ICML-2001-Geibel</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning with Bounded Risk (<abbr title="Peter Geibel">PG</abbr>), pp. 162–169.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-GhavamzadehM.html">ICML-2001-GhavamzadehM</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Continuous-Time Hierarchical Reinforcement Learning (<abbr title="Mohammad Ghavamzadeh">MG</abbr>, <abbr title="Sridhar Mahadevan">SM</abbr>), pp. 186–193.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-GlickmanS.html">ICML-2001-GlickmanS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/memory%20management.html" title="memory management">#memory management</a></span> <span class="tag"><a href="../tag/policy.html" title="policy">#policy</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span> <span class="tag"><a href="../tag/search-based.html" title="search-based">#search-based</a></span></dt><dd>Evolutionary Search, Stochastic Policies with Memory, and Reinforcement Learning with Hidden State (<abbr title="Matthew R. Glickman">MRG</abbr>, <abbr title="Katia P. Sycara">KPS</abbr>), pp. 194–201.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-McGovernB.html">ICML-2001-McGovernB</a> <span class="tag"><a href="../tag/automation.html" title="automation">#automation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Automatic Discovery of Subgoals in Reinforcement Learning using Diverse Density (<abbr title="Amy McGovern">AM</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>), pp. 361–368.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-PerkinsB.html">ICML-2001-PerkinsB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/set.html" title="set">#set</a></span></dt><dd>Lyapunov-Constrained Action Sets for Reinforcement Learning (<abbr title="Theodore J. Perkins">TJP</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>), pp. 409–416.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-SatoK.html">ICML-2001-SatoK</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/markov.html" title="markov">#markov</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Average-Reward Reinforcement Learning for Variance Penalized Markov Decision Problems (<abbr title="Makoto Sato">MS</abbr>, <abbr title="Shigenobu Kobayashi">SK</abbr>), pp. 473–480.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-StoneS.html">ICML-2001-StoneS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Reinforcement Learning toward RoboCup Soccer (<abbr title="Peter Stone">PS</abbr>, <abbr title="Richard S. Sutton">RSS</abbr>), pp. 537–544.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-Wiering.html">ICML-2001-Wiering</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Reinforcement Learning in Dynamic Environments using Instantiated Information (<abbr title="Marco Wiering">MW</abbr>), pp. 585–592.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2001-Wyatt.html">ICML-2001-Wyatt</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Exploration Control in Reinforcement Learning using Optimistic Model Selection (<abbr title="Jeremy L. Wyatt">JLW</abbr>), pp. 593–600.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/sac.png" alt="SAC"/><a href="../SAC-2001-KallesK.html">SAC-2001-KallesK</a> <span class="tag"><a href="../tag/design.html" title="design">#design</a></span> <span class="tag"><a href="../tag/game%20studies.html" title="game studies">#game studies</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/on%20the.html" title="on the">#on the</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span> <span class="tag"><a href="../tag/verification.html" title="verification">#verification</a></span></dt><dd>On verifying game designs and playing strategies using reinforcement learning (<abbr title="Dimitrios Kalles">DK</abbr>, <abbr title="Panagiotis Kanellopoulos">PK</abbr>), pp. 6–11.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/iceis.png" alt="ICEIS"/><a href="../ICEIS-2000-KleinerSB.html">ICEIS-2000-KleinerSB</a> <span class="tag"><a href="../tag/estimation.html" title="estimation">#estimation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Self Organizing Maps for Value Estimation to Solve Reinforcement Learning Tasks (<abbr title="A. Kleiner">AK</abbr>, <abbr title="Bernadette Sharp">BS</abbr>, <abbr title="O. Bittel">OB</abbr>), pp. 149–156.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/cikm.png" alt="CIKM"/><a href="../CIKM-2000-Leuski.html">CIKM-2000-Leuski</a> <span class="tag"><a href="../tag/interactive.html" title="interactive">#interactive</a></span></dt><dd>Relevance and Reinforcement in Interactive Browsing (<abbr title="Anton Leuski">AL</abbr>), pp. 119–126.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-BaxterB.html">ICML-2000-BaxterB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning in POMDP’s via Direct Gradient Ascent (<abbr title="Jonathan Baxter">JB</abbr>, <abbr title="Peter L. Bartlett">PLB</abbr>), pp. 41–48.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-Bowling.html">ICML-2000-Bowling</a> <span class="tag"><a href="../tag/convergence.html" title="convergence">#convergence</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Convergence Problems of General-Sum Multiagent Reinforcement Learning (<abbr title="Michael H. Bowling">MHB</abbr>), pp. 89–94.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-DeJong.html">ICML-2000-DeJong</a> <span class="tag"><a href="../tag/empirical.html" title="empirical">#empirical</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Hidden Strengths and Limitations: An Empirical Investigation of Reinforcement Learning (<abbr title="Gerald DeJong">GD</abbr>), pp. 215–222.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-HougenGS.html">ICML-2000-HougenGS</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>An Integrated Connectionist Approach to Reinforcement Learning for Robotic Control (<abbr title="Dean F. Hougen">DFH</abbr>, <abbr title="Maria L. Gini">MLG</abbr>, <abbr title="James R. Slagle">JRS</abbr>), pp. 383–390.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-LagoudakisL.html">ICML-2000-LagoudakisL</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Algorithm Selection using Reinforcement Learning (<abbr title="Michail G. Lagoudakis">MGL</abbr>, <abbr title="Michael L. Littman">MLL</abbr>), pp. 511–518.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-LauerR.html">ICML-2000-LauerR</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/distributed.html" title="distributed">#distributed</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>An Algorithm for Distributed Reinforcement Learning in Cooperative Multi-Agent Systems (<abbr title="Martin Lauer">ML</abbr>, <abbr title="Martin A. Riedmiller">MAR</abbr>), pp. 535–542.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-MorimotoD.html">ICML-2000-MorimotoD</a> <span class="tag"><a href="../tag/behaviour.html" title="behaviour">#behaviour</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Acquisition of Stand-up Behavior by a Real Robot using Hierarchical Reinforcement Learning (<abbr title="Jun Morimoto">JM</abbr>, <abbr title="Kenji Doya">KD</abbr>), pp. 623–630.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-NgR.html">ICML-2000-NgR</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Algorithms for Inverse Reinforcement Learning (<abbr title="Andrew Y. Ng">AYN</abbr>, <abbr title="Stuart J. Russell">SJR</abbr>), pp. 663–670.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-Randlov.html">ICML-2000-Randlov</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/physics.html" title="physics">#physics</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Shaping in Reinforcement Learning by Changing the Physics of the Problem (<abbr title="Jette Randløv">JR</abbr>), pp. 767–774.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-RandlovBR.html">ICML-2000-RandlovBR</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Combining Reinforcement Learning with a Local Control Algorithm (<abbr title="Jette Randløv">JR</abbr>, <abbr title="Andrew G. Barto">AGB</abbr>, <abbr title="Michael T. Rosenstein">MTR</abbr>), pp. 775–782.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-Reynolds.html">ICML-2000-Reynolds</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Adaptive Resolution Model-Free Reinforcement Learning: Decision Boundary Partitioning (<abbr title="Stuart I. Reynolds">SIR</abbr>), pp. 783–790.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-RichterS.html">ICML-2000-RichterS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span></dt><dd>Knowledge Propagation in Model-based Reinforcement Learning Tasks (<abbr title="Corinna Richter">CR</abbr>, <abbr title="Jörg Stachowiak">JS</abbr>), pp. 791–798.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-RyanR.html">ICML-2000-RyanR</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Learning to Fly: An Application of Hierarchical Reinforcement Learning (<abbr title="Malcolm R. K. Ryan">MRKR</abbr>, <abbr title="Mark D. Reid">MDR</abbr>), pp. 807–814.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-SmartK.html">ICML-2000-SmartK</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Practical Reinforcement Learning in Continuous Spaces (<abbr title="William D. Smart">WDS</abbr>, <abbr title="Leslie Pack Kaelbling">LPK</abbr>), pp. 903–910.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-Strens.html">ICML-2000-Strens</a> <span class="tag"><a href="../tag/framework.html" title="framework">#framework</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Bayesian Framework for Reinforcement Learning (<abbr title="Malcolm J. A. Strens">MJAS</abbr>), pp. 943–950.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-TellerV.html">ICML-2000-TellerV</a> <span class="tag"><a href="../tag/evolution.html" title="evolution">#evolution</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/programming.html" title="programming">#programming</a></span></dt><dd>Efficient Learning Through Evolution: Neural Programming and Internal Reinforcement (<abbr title="Astro Teller">AT</abbr>, <abbr title="Manuela M. Veloso">MMV</abbr>), pp. 959–966.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2000-Wiering.html">ICML-2000-Wiering</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-Agent Reinforcement Leraning for Traffic Light Control (<abbr title="Marco Wiering">MW</abbr>), pp. 1151–1158.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/hci.png" alt="HCI"/><a href="../HCI-EI-1999-TanoT.html">HCI-EI-1999-TanoT</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/user%20interface.html" title="user interface">#user interface</a></span></dt><dd>User Adaptation of the Pen-based User Interface by Reinforcement Learning (<abbr title="Shun'ichi Tano">ST</abbr>, <abbr title="Mitsuru Tsukiyama">MT</abbr>), pp. 233–237.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1999-AbeL.html">ICML-1999-AbeL</a> <span class="tag"><a href="../tag/concept.html" title="concept">#concept</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Associative Reinforcement Learning using Linear Probabilistic Concepts (<abbr title="Naoki Abe">NA</abbr>, <abbr title="Philip M. Long">PML</abbr>), pp. 3–11.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1999-PriceB.html">ICML-1999-PriceB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Implicit Imitation in Multiagent Reinforcement Learning (<abbr title="Bob Price">BP</abbr>, <abbr title="Craig Boutilier">CB</abbr>), pp. 325–334.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1999-RennieM.html">ICML-1999-RennieM</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span> <span class="tag"><a href="../tag/web.html" title="web">#web</a></span></dt><dd>Using Reinforcement Learning to Spider the Web Efficiently (<abbr title="Jason Rennie">JR</abbr>, <abbr title="Andrew McCallum">AM</abbr>), pp. 335–343.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/iclp.png" alt="ICLP"/><a href="../ICLP-1999-SatoF.html">ICLP-1999-SatoF</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/logic%20programming.html" title="logic programming">#logic programming</a></span></dt><dd>Reactive Logic Programming by Reinforcement Learning (<abbr title="Taisuke Sato">TS</abbr>, <abbr title="Satoshi Funada">SF</abbr>), p. 617.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-Dietterich.html">ICML-1998-Dietterich</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>The MAXQ Method for Hierarchical Reinforcement Learning (<abbr title="Thomas G. Dietterich">TGD</abbr>), pp. 118–126.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-DzeroskiRB.html">ICML-1998-DzeroskiRB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/relational.html" title="relational">#relational</a></span></dt><dd>Relational Reinforcement Learning (<abbr title="Saso Dzeroski">SD</abbr>, <abbr title="Luc De Raedt">LDR</abbr>, <abbr title="Hendrik Blockeel">HB</abbr>), pp. 136–143.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-GaborKS.html">ICML-1998-GaborKS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-criteria Reinforcement Learning (<abbr title="Zoltán Gábor">ZG</abbr>, <abbr title="Zsolt Kalmár">ZK</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>), pp. 197–205.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-GarciaN.html">ICML-1998-GarciaN</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Learning Rate Analysis of Reinforcement Learning Algorithms in Finite-Horizon (<abbr title="Frédérick Garcia">FG</abbr>, <abbr title="Seydina M. Ndiaye">SMN</abbr>), pp. 215–223.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-HuW.html">ICML-1998-HuW</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/framework.html" title="framework">#framework</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multiagent Reinforcement Learning: Theoretical Framework and an Algorithm (<abbr title="Junling Hu">JH</abbr>, <abbr title="Michael P. Wellman">MPW</abbr>), pp. 242–250.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-KearnsS.html">ICML-1998-KearnsS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Near-Optimal Reinforcement Learning in Polynominal Time (<abbr title="Michael J. Kearns">MJK</abbr>, <abbr title="Satinder P. Singh">SPS</abbr>), pp. 260–268.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-KimuraK.html">ICML-1998-KimuraK</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>An Analysis of Actor/Critic Algorithms Using Eligibility Traces: Reinforcement Learning with Imperfect Value Function (<abbr title="Hajime Kimura">HK</abbr>, <abbr title="Shigenobu Kobayashi">SK</abbr>), pp. 278–286.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-PendrithM.html">ICML-1998-PendrithM</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/markov.html" title="markov">#markov</a></span></dt><dd>An Analysis of Direct Reinforcement Learning in Non-Markovian Domains (<abbr title="Mark D. Pendrith">MDP</abbr>, <abbr title="Michael McGarity">MM</abbr>), pp. 421–429.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-RandlovA.html">ICML-1998-RandlovA</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Learning to Drive a Bicycle Using Reinforcement Learning and Shaping (<abbr title="Jette Randløv">JR</abbr>, <abbr title="Preben Alstrøm">PA</abbr>), pp. 463–471.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-RyanP.html">ICML-1998-RyanP</a> <span class="tag"><a href="../tag/architecture.html" title="architecture">#architecture</a></span> <span class="tag"><a href="../tag/composition.html" title="composition">#composition</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/named.html" title="named">#named</a></span></dt><dd>RL-TOPS: An Architecture for Modularity and Re-Use in Reinforcement Learning (<abbr title="Malcolm R. K. Ryan">MRKR</abbr>, <abbr title="Mark D. Pendrith">MDP</abbr>), pp. 481–487.</dd> <div class="pagevis" style="width:6px"></div>
<dt><img src="../stuff/icpr.png" alt="ICPR"/><a href="../ICPR-1998-PengB.html">ICPR-1998-PengB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/recognition.html" title="recognition">#recognition</a></span></dt><dd>Local reinforcement learning for object recognition (<abbr title="Jing Peng">JP</abbr>, <abbr title="Bir Bhanu">BB</abbr>), pp. 272–274.</dd> <div class="pagevis" style="width:2px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1997-Fiechter.html">ICML-1997-Fiechter</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>Expected Mistake Bound Model for On-Line Reinforcement Learning (<abbr title="Claude-Nicolas Fiechter">CNF</abbr>), pp. 116–124.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1997-KimuraMK.html">ICML-1997-KimuraMK</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning in POMDPs with Function Approximation (<abbr title="Hajime Kimura">HK</abbr>, <abbr title="Kazuteru Miyazaki">KM</abbr>, <abbr title="Shigenobu Kobayashi">SK</abbr>), pp. 152–160.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1997-PrecupS.html">ICML-1997-PrecupS</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Exponentiated Gradient Methods for Reinforcement Learning (<abbr title="Doina Precup">DP</abbr>, <abbr title="Richard S. Sutton">RSS</abbr>), pp. 272–277.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1997-TadepalliD.html">ICML-1997-TadepalliD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Hierarchical Explanation-Based Reinforcement Learning (<abbr title="Prasad Tadepalli">PT</abbr>, <abbr title="Thomas G. Dietterich">TGD</abbr>), pp. 358–366.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-GoetzKM.html">ICML-1996-GoetzKM</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning (<abbr title="Patrick Goetz">PG</abbr>, <abbr title="Shailesh Kumar">SK</abbr>, <abbr title="Risto Miikkulainen">RM</abbr>), pp. 175–181.</dd> <div class="pagevis" style="width:6px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-LittmanS.html">ICML-1996-LittmanS</a> <span class="tag"><a href="../tag/convergence.html" title="convergence">#convergence</a></span></dt><dd>A Generalized Reinforcement-Learning Model: Convergence and Applications (<abbr title="Michael L. Littman">MLL</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>), pp. 310–318.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-Mahadevan.html">ICML-1996-Mahadevan</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Sensitive Discount Optimality: Unifying Discounted and Average Reward Reinforcement Learning (<abbr title="Sridhar Mahadevan">SM</abbr>), pp. 328–336.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-Moore.html">ICML-1996-Moore</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Reinforcement Learning in Factories: The Auton Project (Abstract) (<abbr title="Andrew W. Moore 0001">AWM0</abbr>), p. 556.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-Munos.html">ICML-1996-Munos</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/convergence.html" title="convergence">#convergence</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Convergent Reinforcement Learning Algorithm in the Continuous Case: The Finite-Element Reinforcement Learning (<abbr title="Rémi Munos">RM</abbr>), pp. 337–345.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-PendrithR.html">ICML-1996-PendrithR</a> <span class="tag"><a href="../tag/difference.html" title="difference">#difference</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Actual Return Reinforcement Learning versus Temporal Differences: Some Theoretical and Experimental Results (<abbr title="Mark D. Pendrith">MDP</abbr>, <abbr title="Malcolm R. K. Ryan">MRKR</abbr>), pp. 373–381.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1996-TadepalliO.html">ICML-1996-TadepalliO</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/domain%20model.html" title="domain model">#domain model</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Up Average Reward Reinforcement Learning by Approximating the Domain Models and the Value Function (<abbr title="Prasad Tadepalli">PT</abbr>, <abbr title="DoKyeong Ok">DO</abbr>), pp. 471–479.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icpr.png" alt="ICPR"/><a href="../ICPR-1996-PengB.html">ICPR-1996-PengB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/recognition.html" title="recognition">#recognition</a></span></dt><dd>Delayed reinforcement learning for closed-loop object recognition (<abbr title="Jing Peng">JP</abbr>, <abbr title="Bir Bhanu">BB</abbr>), pp. 310–314.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-Baird.html">ICML-1995-Baird</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Residual Algorithms: Reinforcement Learning with Function Approximation (<abbr title="Leemon C. Baird III">LCBI</abbr>), pp. 30–37.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-CichoszM.html">ICML-1995-CichoszM</a> <span class="tag"><a href="../tag/difference.html" title="difference">#difference</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Fast and Efficient Reinforcement Learning with Truncated Temporal Differences (<abbr title="Pawel Cichosz">PC</abbr>, <abbr title="Jan J. Mulawka">JJM</abbr>), pp. 99–107.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-DietterichF.html">ICML-1995-DietterichF</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Explanation-Based Learning and Reinforcement Learning: A Unified View (<abbr title="Thomas G. Dietterich">TGD</abbr>, <abbr title="Nicholas S. Flann">NSF</abbr>), pp. 176–184.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-GambardellaD.html">ICML-1995-GambardellaD</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/named.html" title="named">#named</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Ant-Q: A Reinforcement Learning Approach to the Traveling Salesman Problem (<abbr title="Luca Maria Gambardella">LMG</abbr>, <abbr title="Marco Dorigo">MD</abbr>), pp. 252–260.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-KimuraYK.html">ICML-1995-KimuraYK</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span></dt><dd>Reinforcement Learning by Stochastic Hill Climbing on Discounted Reward (<abbr title="Hajime Kimura">HK</abbr>, <abbr title="Masayuki Yamamura">MY</abbr>, <abbr title="Shigenobu Kobayashi">SK</abbr>), pp. 295–303.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-McCallum.html">ICML-1995-McCallum</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Instance-Based Utile Distinctions for Reinforcement Learning with Hidden State (<abbr title="Andrew McCallum">AM</abbr>), pp. 387–395.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1994-Littman.html">ICML-1994-Littman</a> <span class="tag"><a href="../tag/framework.html" title="framework">#framework</a></span> <span class="tag"><a href="../tag/game%20studies.html" title="game studies">#game studies</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/markov.html" title="markov">#markov</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Markov Games as a Framework for Multi-Agent Reinforcement Learning (<abbr title="Michael L. Littman">MLL</abbr>), pp. 157–163.</dd> <div class="pagevis" style="width:6px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1994-Mahadevan.html">ICML-1994-Mahadevan</a> <span class="tag"><a href="../tag/case%20study.html" title="case study">#case study</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>To Discount or Not to Discount in Reinforcement Learning: A Case Study Comparing R Learning and Q Learning (<abbr title="Sridhar Mahadevan">SM</abbr>), pp. 164–172.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/dac.png" alt="DAC"/><a href="../DAC-1993-LewisP.html">DAC-1993-LewisP</a></dt><dd>A Negative Reinforcement Method for PGA Routing (<abbr title="Forbes D. Lewis">FDL</abbr>, <abbr title="Wang Chia-Chi Pong">WCCP</abbr>), pp. 601–605.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1993-Lin.html">ICML-1993-Lin</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Up Reinforcement Learning for Robot Control (<abbr title="Long Ji Lin">LJL</abbr>), pp. 182–189.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1993-Schwartz.html">ICML-1993-Schwartz</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Reinforcement Learning Method for Maximizing Undiscounted Rewards (<abbr title="Anton Schwartz">AS</abbr>), pp. 298–305.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1993-Tan.html">ICML-1993-Tan</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-Agent Reinforcement Learning: Independent versus Cooperative Agents (<abbr title="Ming Tan">MT</abbr>), pp. 330–337.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1992-ClouseU.html">ML-1992-ClouseU</a> <span class="tag"><a href="../tag/education.html" title="education">#education</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>A Teaching Method for Reinforcement Learning (<abbr title="Jeffery A. Clouse">JAC</abbr>, <abbr title="Paul E. Utgoff">PEU</abbr>), pp. 92–110.</dd> <div class="pagevis" style="width:18px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1992-Mahadevan.html">ML-1992-Mahadevan</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span></dt><dd>Enhancing Transfer in Reinforcement Learning by Building Stochastic Models of Robot Actions (<abbr title="Sridhar Mahadevan">SM</abbr>), pp. 290–299.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1992-McCallum.html">ML-1992-McCallum</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/proximity.html" title="proximity">#proximity</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Using Transitional Proximity for Faster Reinforcement Learning (<abbr title="Andrew McCallum">AM</abbr>), pp. 316–321.</dd> <div class="pagevis" style="width:5px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1992-Singh.html">ML-1992-Singh</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Reinforcement Learning Algorithms by Learning Variable Temporal Resolution Models (<abbr title="Satinder P. Singh">SPS</abbr>), pp. 406–415.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-Berenji.html">ML-1991-Berenji</a> <span class="tag"><a href="../tag/approximate.html" title="approximate">#approximate</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/refinement.html" title="refinement">#refinement</a></span></dt><dd>Refinement of Approximate Reasoning-based Controllers by Reinforcement Learning (<abbr title="Hamid R. Berenji">HRB</abbr>), pp. 475–479.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-Lin.html">ML-1991-Lin</a> <span class="tag"><a href="../tag/education.html" title="education">#education</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/self.html" title="self">#self</a></span></dt><dd>Self-improvement Based on Reinforcement Learning, Planning and Teaching (<abbr title="Long Ji Lin">LJL</abbr>), pp. 323–327.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-MahadevanC.html">ML-1991-MahadevanC</a> <span class="tag"><a href="../tag/architecture.html" title="architecture">#architecture</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Reinforcement Learning to Robotics by Exploiting the Subsumption Architecture (<abbr title="Sridhar Mahadevan">SM</abbr>, <abbr title="Jonathan Connell">JC</abbr>), pp. 328–332.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-MillanT.html">ML-1991-MillanT</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Learning to Avoid Obstacles Through Reinforcement (<abbr title="José del R. Millán">JdRM</abbr>, <abbr title="Carme Torras">CT</abbr>), pp. 298–302.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-Tan.html">ML-1991-Tan</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/representation.html" title="representation">#representation</a></span></dt><dd>Learning a Cost-Sensitive Internal Representation for Reinforcement Learning (<abbr title="Ming Tan">MT</abbr>), pp. 358–362.</dd> <div class="pagevis" style="width:4px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1991-Wixson.html">ML-1991-Wixson</a> <span class="tag"><a href="../tag/composition.html" title="composition">#composition</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Scaling Reinforcement Learning Techniques via Modularity (<abbr title="Lambert E. Wixson">LEW</abbr>), pp. 3368–372.</dd> <div class="pagevis" style="width:-2996px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1990-Kaelbling.html">ML-1990-Kaelbling</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Learning Functions in k-DNF from Reinforcement (<abbr title="Leslie Pack Kaelbling">LPK</abbr>), pp. 162–169.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1990-WhiteheadB.html">ML-1990-WhiteheadB</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Active Perception and Reinforcement Learning (<abbr title="Steven D. Whitehead">SDW</abbr>, <abbr title="Dana H. Ballard">DHB</abbr>), pp. 179–188.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ML-1988-Lynne.html">ML-1988-Lynne</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Competitive Reinforcement Learning (<abbr title="Kenton J. Lynne">KJL</abbr>), pp. 188–199.</dd> <div class="pagevis" style="width:11px"></div></dl>
</div>
<hr style="clear:both"/>
<div class="last">
	<em>
		<a href="http://bibtex.github.io">Bibliography of Software Language Engineering in Generated Hypertext</a>
		(<a href="http://github.com/slebok/bibsleigh">BibSLEIGH</a>) is
		created and maintained by <a href="http://grammarware.github.io/">Dr. Vadim Zaytsev</a>.<br/>
		Hosted as a part of <a href="http://slebok.github.io/">SLEBOK</a> on <a href="http://www.github.com/">GitHub</a>.
	</em>
</div>
</body>
</html>