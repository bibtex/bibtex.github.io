<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
	<meta name="keywords" content="software linguistics, software language engineering, book of knowledge, glossary, academic publications, scientific research, open knowledge, open science"/>
	<title>BibSLEIGH — bandit stem</title>
	<link href="../stuff/bib.css" rel="stylesheet" type="text/css"/>
	<link href='http://fonts.googleapis.com/css?family=Exo+2:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	<script src="../stuff/jquery.min.js" type="text/javascript"></script>
</head>
<body>
<div class="left">
	<a href="../index.html"><img src="../stuff/bibsleigh.png" alt="BibSLEIGH" title="BibSLEIGH" class="pad"/></a>

	<div class="pad">
		<a href="../index.html"><img src="../stuff/p-corpus.png" alt="BibSLEIGH corpus" title="All papers in the corpus"/></a><br/>
		<a href="../tag/index.html"><img src="../stuff/p-tags.png" alt="BibSLEIGH tags" title="All known tags"/></a><br/>
		<a href="../bundle/index.html"><img src="../stuff/p-bundles.png" alt="BibSLEIGH bundles" title="All selected bundles"/></a><br/>
		<a href="../person/index.html"><img src="../stuff/p-people.png" alt="BibSLEIGH people" title="All contributors"/></a>
	</div>
	<a href="http://creativecommons.org/licenses/by/4.0/" title="CC-BY"><img src="../stuff/cc-by.png" alt="CC-BY"/></a><br/>
	<a href="http://opendatacommons.org/licenses/by/summary/" title="Open Knowledge"><img src="../stuff/open-knowledge.png" alt="Open Knowledge" /></a><br/>
	<a href="http://validator.w3.org/check/referer" title="XHTML 1.0 W3C Rec"><img src="../stuff/xhtml.png" alt="XHTML 1.0 W3C Rec" /></a><br/>
	<a href="http://jigsaw.w3.org/css-validator/check/referer" title="CSS 2.1 W3C CanRec"><img src="../stuff/css.png" alt="CSS 2.1 W3C CanRec" class="pad" /></a><br/>
	<div class="sm">
		<a href="../mailto:vadim@grammarware.net"><img src="../stuff/email.png" alt="email" title="Complain!" /></a>
		<a href="https://twitter.com/intent/tweet?screen_name=grammarware"><img src="../stuff/twitter.png" alt="twitter" title="Mention!" /></a>
	</div>

</div>
<div class="main">
<div class="tbox">
<code>Used together with:</code><hr/><span class="tag"><a href="arm.html">arm</a></span> (20)
<br/><span class="tag"><a href="multi.html">multi</a></span> (15)
<br/><span class="tag"><a href="learn.html">learn</a></span> (10)
<br/><span class="tag"><a href="problem.html">problem</a></span> (10)
<br/><span class="tag"><a href="regret.html">regret</a></span> (9)
</div>
<h2><span class="ttl">Stem</span> bandit$ (<a href="../words.html">all stems</a>)</h2>
<h3>62 papers:</h3>
<dl class="toc"><dt><img src="../stuff/case.png" alt="CASE"/><a href="../CASE-2015-LaskeyMMPPBKAG.html">CASE-2015-LaskeyMMPPBKAG</a> <span class="tag"><a href="../tag/2d.html" title="2d">#2d</a></span> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/nondeterminism.html" title="nondeterminism">#nondeterminism</a></span></dt><dd>Multi-armed bandit models for 2D grasp planning with uncertainty (<abbr title="Michael Laskey">ML</abbr>, <abbr title="Jeffrey Mahler">JM</abbr>, <abbr title="Zoe McCarthy">ZM</abbr>, <abbr title="Florian T. Pokorny">FTP</abbr>, <abbr title="Sachin Patil">SP</abbr>, <abbr title="Jur P. van den Berg">JPvdB</abbr>, <abbr title="Danica Kragic">DK</abbr>, <abbr title="Pieter Abbeel">PA</abbr>, <abbr title="Ken Goldberg">KG</abbr>), pp. 572–579.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/iceis.png" alt="ICEIS"/><a href="../ICEIS-v1-2015-BurtiniLL.html">ICEIS-v1-2015-BurtiniLL</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>Improving Online Marketing Experiments with Drifting Multi-armed Bandits (<abbr title="Giuseppe Burtini">GB</abbr>, <abbr title="Jason Loeppky">JL</abbr>, <abbr title="Ramon Lawrence">RL</abbr>), pp. 630–636.</dd> <div class="pagevis" style="width:6px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-CarpentierV.html">ICML-2015-CarpentierV</a> <span class="tag"><a href="../tag/infinity.html" title="infinity">#infinity</a></span></dt><dd>Simple regret for infinitely many armed bandits (<abbr title="Alexandra Carpentier">AC</abbr>, <abbr title="Michal Valko">MV</abbr>), pp. 1133–1141.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-GajaneUC.html">ICML-2015-GajaneUC</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/exponential.html" title="exponential">#exponential</a></span></dt><dd>A Relative Exponential Weighing Algorithm for Adversarial Utility-based Dueling Bandits (<abbr title="Pratik Gajane">PG</abbr>, <abbr title="Tanguy Urvoy">TU</abbr>, <abbr title="Fabrice Clérot">FC</abbr>), pp. 218–227.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-HanawalSVM.html">ICML-2015-HanawalSVM</a></dt><dd>Cheap Bandits (<abbr title="Manjesh Kumar Hanawal">MKH</abbr>, <abbr title="Venkatesh Saligrama">VS</abbr>, <abbr title="Michal Valko">MV</abbr>, <abbr title="Rémi Munos">RM</abbr>), pp. 2133–2142.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-KandasamySP.html">ICML-2015-KandasamySP</a> <span class="tag"><a href="../tag/modelling.html" title="modelling">#modelling</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span></dt><dd>High Dimensional Bayesian Optimisation and Bandits via Additive Models (<abbr title="Kirthevasan Kandasamy">KK</abbr>, <abbr title="Jeff G. Schneider">JGS</abbr>, <abbr title="Barnabás Póczos">BP</abbr>), pp. 295–304.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-KomiyamaHN.html">ICML-2015-KomiyamaHN</a> <span class="tag"><a href="../tag/analysis.html" title="analysis">#analysis</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Optimal Regret Analysis of Thompson Sampling in Stochastic Multi-armed Bandit Problem with Multiple Plays (<abbr title="Junpei Komiyama">JK</abbr>, <abbr title="Junya Honda">JH</abbr>, <abbr title="Hiroshi Nakagawa">HN</abbr>), pp. 1152–1161.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-KvetonSWA.html">ICML-2015-KvetonSWA</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/rank.html" title="rank">#rank</a></span></dt><dd>Cascading Bandits: Learning to Rank in the Cascade Model (<abbr title="Branislav Kveton">BK</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>, <abbr title="Zheng Wen">ZW</abbr>, <abbr title="Azin Ashkan">AA</abbr>), pp. 767–776.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-SwaminathanJ.html">ICML-2015-SwaminathanJ</a> <span class="tag"><a href="../tag/feedback.html" title="feedback">#feedback</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span></dt><dd>Counterfactual Risk Minimization: Learning from Logged Bandit Feedback (<abbr title="Adith Swaminathan">AS</abbr>, <abbr title="Thorsten Joachims">TJ</abbr>), pp. 814–823.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-SzorenyiBWH.html">ICML-2015-SzorenyiBWH</a> <span class="tag"><a href="../tag/approach.html" title="approach">#approach</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Qualitative Multi-Armed Bandits: A Quantile-Based Approach (<abbr title="Balázs Szörényi">BS</abbr>, <abbr title="Róbert Busa-Fekete">RBF</abbr>, <abbr title="Paul Weng">PW</abbr>, <abbr title="Eyke Hüllermeier">EH</abbr>), pp. 1660–1668.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2015-WenKA.html">ICML-2015-WenKA</a> <span class="tag"><a href="../tag/combinator.html" title="combinator">#combinator</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Efficient Learning in Large-Scale Combinatorial Semi-Bandits (<abbr title="Zheng Wen">ZW</abbr>, <abbr title="Branislav Kveton">BK</abbr>, <abbr title="Azin Ashkan">AA</abbr>), pp. 1113–1122.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/sigir.png" alt="SIGIR"/><a href="../SIGIR-2015-TangJLZL.html">SIGIR-2015-TangJLZL</a> <span class="tag"><a href="../tag/personalisation.html" title="personalisation">#personalisation</a></span> <span class="tag"><a href="../tag/recommendation.html" title="recommendation">#recommendation</a></span></dt><dd>Personalized Recommendation via Parameter-Free Contextual Bandits (<abbr title="Liang Tang">LT</abbr>, <abbr title="Yexi Jiang">YJ</abbr>, <abbr title="Lei Li">LL</abbr>, <abbr title="Chunqiu Zeng">CZ</abbr>, <abbr title="Tao Li">TL</abbr>), pp. 323–332.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/stoc.png" alt="STOC"/><a href="../STOC-2014-DekelDKP.html">STOC-2014-DekelDKP</a></dt><dd>Bandits with switching costs: T2/3 regret (<abbr title="Ofer Dekel">OD</abbr>, <abbr title="Jian Ding">JD</abbr>, <abbr title="Tomer Koren">TK</abbr>, <abbr title="Yuval Peres">YP</abbr>), pp. 459–467.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/cikm.png" alt="CIKM"/><a href="../CIKM-2014-NguyenL.html">CIKM-2014-NguyenL</a> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Dynamic Clustering of Contextual Multi-Armed Bandits (<abbr title="Trong T. Nguyen">TTN</abbr>, <abbr title="Hady Wirawan Lauw">HWL</abbr>), pp. 1959–1962.</dd> <div class="pagevis" style="width:3px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2014-ChenLL.html">ICML-c1-2014-ChenLL</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Boosting with Online Binary Learners for the Multiclass Bandit Problem (<abbr title="Shang-Tse Chen">STC</abbr>, <abbr title="Hsuan-Tien Lin">HTL</abbr>, <abbr title="Chi-Jen Lu">CJL</abbr>), pp. 342–350.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2014-CombesP.html">ICML-c1-2014-CombesP</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span></dt><dd>Unimodal Bandits: Regret Lower Bounds and Optimal Algorithms (<abbr title="Richard Combes">RC</abbr>, <abbr title="Alexandre Proutiere">AP</abbr>), pp. 521–529.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2014-MaillardM.html">ICML-c1-2014-MaillardM</a></dt><dd>Latent Bandits (<abbr title="Odalric-Ambrym Maillard">OAM</abbr>, <abbr title="Shie Mannor">SM</abbr>), pp. 136–144.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2014-SeldinBCA.html">ICML-c1-2014-SeldinBCA</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/predict.html" title="predict">#predict</a></span></dt><dd>Prediction with Limited Advice and Multiarmed Bandits with Paid Observations (<abbr title="Yevgeny Seldin">YS</abbr>, <abbr title="Peter L. Bartlett">PLB</abbr>, <abbr title="Koby Crammer">KC</abbr>, <abbr title="Yasin Abbasi-Yadkori">YAY</abbr>), pp. 280–287.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-AgarwalHKLLS.html">ICML-c2-2014-AgarwalHKLLS</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits (<abbr title="Alekh Agarwal">AA</abbr>, <abbr title="Daniel Hsu">DH</abbr>, <abbr title="Satyen Kale">SK</abbr>, <abbr title="John Langford">JL</abbr>, <abbr title="Lihong Li">LL</abbr>, <abbr title="Robert E. Schapire">RES</abbr>), pp. 1638–1646.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-AilonKJ.html">ICML-c2-2014-AilonKJ</a></dt><dd>Reducing Dueling Bandits to Cardinal Bandits (<abbr title="Nir Ailon">NA</abbr>, <abbr title="Zohar Shay Karnin">ZSK</abbr>, <abbr title="Thorsten Joachims">TJ</abbr>), pp. 856–864.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-AzarLB.html">ICML-c2-2014-AzarLB</a> <span class="tag"><a href="../tag/correlation.html" title="correlation">#correlation</a></span> <span class="tag"><a href="../tag/feedback.html" title="feedback">#feedback</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span></dt><dd>Online Stochastic Optimization under Correlated Bandit Feedback (<abbr title="Mohammad Gheshlaghi Azar">MGA</abbr>, <abbr title="Alessandro Lazaric">AL</abbr>, <abbr title="Emma Brunskill">EB</abbr>), pp. 1557–1565.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-GentileLZ.html">ICML-c2-2014-GentileLZ</a> <span class="tag"><a href="../tag/clustering.html" title="clustering">#clustering</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span></dt><dd>Online Clustering of Bandits (<abbr title="Claudio Gentile">CG</abbr>, <abbr title="Shuai Li">SL</abbr>, <abbr title="Giovanni Zappella">GZ</abbr>), pp. 757–765.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-MaryPN.html">ICML-c2-2014-MaryPN</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/evaluation.html" title="evaluation">#evaluation</a></span></dt><dd>Improving offline evaluation of contextual bandit algorithms via bootstrapping techniques (<abbr title="Jérémie Mary">JM</abbr>, <abbr title="Philippe Preux">PP</abbr>, <abbr title="Olivier Nicol">ON</abbr>), pp. 172–180.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-NeufeldGSS.html">ICML-c2-2014-NeufeldGSS</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/monte%20carlo.html" title="monte carlo">#monte carlo</a></span></dt><dd>Adaptive Monte Carlo via Bandit Allocation (<abbr title="James Neufeld">JN</abbr>, <abbr title="András György">AG</abbr>, <abbr title="Csaba Szepesvári">CS</abbr>, <abbr title="Dale Schuurmans">DS</abbr>), pp. 1944–1952.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-SeldinS.html">ICML-c2-2014-SeldinS</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span></dt><dd>One Practical Algorithm for Both Stochastic and Adversarial Bandits (<abbr title="Yevgeny Seldin">YS</abbr>, <abbr title="Aleksandrs Slivkins">AS</abbr>), pp. 1287–1295.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-ValkoMKK.html">ICML-c2-2014-ValkoMKK</a> <span class="tag"><a href="../tag/graph.html" title="graph">#graph</a></span></dt><dd>Spectral Bandits for Smooth Graph Functions (<abbr title="Michal Valko">MV</abbr>, <abbr title="Rémi Munos">RM</abbr>, <abbr title="Branislav Kveton">BK</abbr>, <abbr title="Tomás Kocák">TK</abbr>), pp. 46–54.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2014-ZoghiWMR.html">ICML-c2-2014-ZoghiWMR</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Relative Upper Confidence Bound for the K-Armed Dueling Bandit Problem (<abbr title="Masrour Zoghi">MZ</abbr>, <abbr title="Shimon Whiteson">SW</abbr>, <abbr title="Rémi Munos">RM</abbr>, <abbr title="Maarten de Rijke">MdR</abbr>), pp. 10–18.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/kdd.png" alt="KDD"/><a href="../KDD-2014-FangT.html">KDD-2014-FangT</a> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span></dt><dd>Networked bandits with disjoint linear payoffs (<abbr title="Meng Fang">MF</abbr>, <abbr title="Dacheng Tao">DT</abbr>), pp. 1106–1115.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/recsys.png" alt="RecSys"/><a href="../RecSys-2014-TangJLL.html">RecSys-2014-TangJLL</a> <span class="tag"><a href="../tag/personalisation.html" title="personalisation">#personalisation</a></span> <span class="tag"><a href="../tag/recommendation.html" title="recommendation">#recommendation</a></span></dt><dd>Ensemble contextual bandits for personalized recommendation (<abbr title="Liang Tang">LT</abbr>, <abbr title="Yexi Jiang">YJ</abbr>, <abbr title="Lei Li">LL</abbr>, <abbr title="Tao Li">TL</abbr>), pp. 73–80.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2013-AbernethyAKD.html">ICML-c1-2013-AbernethyAKD</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span> <span class="tag"><a href="../tag/scalability.html" title="scalability">#scalability</a></span></dt><dd>Large-Scale Bandit Problems and KWIK Learning (<abbr title="Jacob Abernethy">JA</abbr>, <abbr title="Kareem Amin">KA</abbr>, <abbr title="Michael Kearns">MK</abbr>, <abbr title="Moez Draief">MD</abbr>), pp. 588–596.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2013-BubeckWV.html">ICML-c1-2013-BubeckWV</a> <span class="tag"><a href="../tag/identification.html" title="identification">#identification</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multiple Identifications in Multi-Armed Bandits (<abbr title="Sébastien Bubeck">SB</abbr>, <abbr title="Tengyao Wang">TW</abbr>, <abbr title="Nitin Viswanathan">NV</abbr>), pp. 258–265.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c1-2013-ChenWY.html">ICML-c1-2013-ChenWY</a> <span class="tag"><a href="../tag/combinator.html" title="combinator">#combinator</a></span> <span class="tag"><a href="../tag/framework.html" title="framework">#framework</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Combinatorial Multi-Armed Bandit: General Framework and Applications (<abbr title="Wei Chen">WC</abbr>, <abbr title="Yajun Wang">YW</abbr>, <abbr title="Yang Yuan">YY</abbr>), pp. 151–159.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c2-2013-UrvoyCFN.html">ICML-c2-2013-UrvoyCFN</a></dt><dd>Generic Exploration and K-armed Voting Bandits (<abbr title="Tanguy Urvoy">TU</abbr>, <abbr title="Fabrice Clérot">FC</abbr>, <abbr title="Raphaël Feraud">RF</abbr>, <abbr title="Sami Naamane">SN</abbr>), pp. 91–99.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-AgrawalG.html">ICML-c3-2013-AgrawalG</a> <span class="tag"><a href="../tag/linear.html" title="linear">#linear</a></span></dt><dd>Thompson Sampling for Contextual Bandits with Linear Payoffs (<abbr title="Shipra Agrawal">SA</abbr>, <abbr title="Navin Goyal">NG</abbr>), pp. 127–135.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-KarninKS.html">ICML-c3-2013-KarninKS</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Almost Optimal Exploration in Multi-Armed Bandits (<abbr title="Zohar Shay Karnin">ZSK</abbr>, <abbr title="Tomer Koren">TK</abbr>, <abbr title="Oren Somekh">OS</abbr>), pp. 1238–1246.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-c3-2013-SzorenyiBHOJK.html">ICML-c3-2013-SzorenyiBHOJK</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/distributed.html" title="distributed">#distributed</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span></dt><dd>Gossip-based distributed stochastic bandit algorithms (<abbr title="Balázs Szörényi">BS</abbr>, <abbr title="Róbert Busa-Fekete">RBF</abbr>, <abbr title="István Hegedüs">IH</abbr>, <abbr title="Róbert Ormándi">RO</abbr>, <abbr title="Márk Jelasity">MJ</abbr>, <abbr title="Balázs Kégl">BK</abbr>), pp. 19–27.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/cgo.png" alt="CGO"/><a href="../CGO-2013-EklovNBH.html">CGO-2013-EklovNBH</a> <span class="tag"><a href="../tag/memory%20management.html" title="memory management">#memory management</a></span></dt><dd>Bandwidth Bandit: Quantitative characterization of memory contention (<abbr title="David Eklov">DE</abbr>, <abbr title="Nikos Nikoleris">NN</abbr>, <abbr title="David Black-Schaffer">DBS</abbr>, <abbr title="Erik Hagersten">EH</abbr>), p. 10.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-AvnerMS.html">ICML-2012-AvnerMS</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Decoupling Exploration and Exploitation in Multi-Armed Bandits (<abbr title="Orly Avner">OA</abbr>, <abbr title="Shie Mannor">SM</abbr>, <abbr title="Ohad Shamir">OS</abbr>), p. 145.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-DekelTA.html">ICML-2012-DekelTA</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span> <span class="tag"><a href="../tag/policy.html" title="policy">#policy</a></span></dt><dd>Online Bandit Learning against an Adaptive Adversary: from Regret to Policy Regret (<abbr title="Ofer Dekel">OD</abbr>, <abbr title="Ambuj Tewari">AT</abbr>, <abbr title="Raman Arora">RA</abbr>), p. 227.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-DesautelsKB.html">ICML-2012-DesautelsKB</a> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span> <span class="tag"><a href="../tag/trade-off.html" title="trade-off">#trade-off</a></span></dt><dd>Parallelizing Exploration-Exploitation Tradeoffs with Gaussian Process Bandit Optimization (<abbr title="Thomas Desautels">TD</abbr>, <abbr title="Andreas Krause">AK</abbr>, <abbr title="Joel W. Burdick">JWB</abbr>), p. 109.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-FreitasSZ.html">ICML-2012-FreitasSZ</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/exponential.html" title="exponential">#exponential</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations (<abbr title="Nando de Freitas">NdF</abbr>, <abbr title="Alexander J. Smola">AJS</abbr>, <abbr title="Masrour Zoghi">MZ</abbr>), p. 125.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-KalyanakrishnanTAS.html">ICML-2012-KalyanakrishnanTAS</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/probability.html" title="probability">#probability</a></span> <span class="tag"><a href="../tag/set.html" title="set">#set</a></span></dt><dd>PAC Subset Selection in Stochastic Multi-armed Bandits (<abbr title="Shivaram Kalyanakrishnan">SK</abbr>, <abbr title="Ambuj Tewari">AT</abbr>, <abbr title="Peter Auer">PA</abbr>, <abbr title="Peter Stone">PS</abbr>), p. 34.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2012-YueHG.html">ICML-2012-YueHG</a></dt><dd>Hierarchical Exploration for Accelerating Contextual Bandits (<abbr title="Yisong Yue">YY</abbr>, <abbr title="Sue Ann Hong">SAH</abbr>, <abbr title="Carlos Guestrin">CG</abbr>), p. 128.</dd> <div class="pagevis" style="width:0px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2011-CrammerG.html">ICML-2011-CrammerG</a> <span class="tag"><a href="../tag/adaptation.html" title="adaptation">#adaptation</a></span> <span class="tag"><a href="../tag/classification.html" title="classification">#classification</a></span> <span class="tag"><a href="../tag/feedback.html" title="feedback">#feedback</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Multiclass Classification with Bandit Feedback using Adaptive Regularization (<abbr title="Koby Crammer">KC</abbr>, <abbr title="Claudio Gentile">CG</abbr>), pp. 273–280.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2011-YueJ.html">ICML-2011-YueJ</a></dt><dd>Beat the Mean Bandit (<abbr title="Yisong Yue">YY</abbr>, <abbr title="Thorsten Joachims">TJ</abbr>), pp. 241–248.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2011-YuM.html">ICML-2011-YuM</a></dt><dd>Unimodal Bandits (<abbr title="Jia Yuan Yu">JYY</abbr>, <abbr title="Shie Mannor">SM</abbr>), pp. 41–48.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/kdd.png" alt="KDD"/><a href="../KDD-2011-ValizadeganJW.html">KDD-2011-ValizadeganJW</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/predict.html" title="predict">#predict</a></span></dt><dd>Learning to trade off between exploration and exploitation in multiclass bandit prediction (<abbr title="Hamed Valizadegan">HV</abbr>, <abbr title="Rong Jin">RJ</abbr>, <abbr title="Shijun Wang">SW</abbr>), pp. 204–212.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-Busa-FeketeK.html">ICML-2010-Busa-FeketeK</a> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Fast boosting using adversarial bandits (<abbr title="Róbert Busa-Fekete">RBF</abbr>, <abbr title="Balázs Kégl">BK</abbr>), pp. 143–150.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-KalyanakrishnanS.html">ICML-2010-KalyanakrishnanS</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/theory%20and%20practice.html" title="theory and practice">#theory and practice</a></span></dt><dd>Efficient Selection of Multiple Bandit Arms: Theory and Practice (<abbr title="Shivaram Kalyanakrishnan">SK</abbr>, <abbr title="Peter Stone">PS</abbr>), pp. 511–518.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2010-SrinivasKKS.html">ICML-2010-SrinivasKKS</a> <span class="tag"><a href="../tag/design.html" title="design">#design</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/process.html" title="process">#process</a></span></dt><dd>Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design (<abbr title="Niranjan Srinivas">NS</abbr>, <abbr title="Andreas Krause">AK</abbr>, <abbr title="Sham Kakade">SK</abbr>, <abbr title="Matthias W. Seeger">MWS</abbr>), pp. 1015–1022.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icalp.png" alt="ICALP"/><a href="../ICALP-v2-2009-GuhaM.html">ICALP-v2-2009-GuhaM</a> <span class="tag"><a href="../tag/metric.html" title="metric">#metric</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-armed Bandits with Metric Switching Costs (<abbr title="Sudipto Guha">SG</abbr>, <abbr title="Kamesh Munagala">KM</abbr>), pp. 496–507.</dd> <div class="pagevis" style="width:11px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-MesmayRVP.html">ICML-2009-MesmayRVP</a> <span class="tag"><a href="../tag/graph.html" title="graph">#graph</a></span> <span class="tag"><a href="../tag/library.html" title="library">#library</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span></dt><dd>Bandit-based optimization on graphs with application to library performance tuning (<abbr title="Frédéric de Mesmay">FdM</abbr>, <abbr title="Arpad Rimmel">AR</abbr>, <abbr title="Yevgen Voronenko">YV</abbr>, <abbr title="Markus Püschel">MP</abbr>), pp. 729–736.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-YueJ.html">ICML-2009-YueJ</a> <span class="tag"><a href="../tag/information%20retrieval.html" title="information retrieval">#information retrieval</a></span> <span class="tag"><a href="../tag/optimisation.html" title="optimisation">#optimisation</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Interactively optimizing information retrieval systems as a dueling bandits problem (<abbr title="Yisong Yue">YY</abbr>, <abbr title="Thorsten Joachims">TJ</abbr>), pp. 1201–1208.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2009-YuM.html">ICML-2009-YuM</a> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Piecewise-stationary bandit problems with side observations (<abbr title="Jia Yuan Yu">JYY</abbr>, <abbr title="Shie Mannor">SM</abbr>), pp. 1177–1184.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/stoc.png" alt="STOC"/><a href="../STOC-2008-KleinbergSU.html">STOC-2008-KleinbergSU</a> <span class="tag"><a href="../tag/metric.html" title="metric">#metric</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span></dt><dd>Multi-armed bandits in metric spaces (<abbr title="Robert Kleinberg">RK</abbr>, <abbr title="Aleksandrs Slivkins">AS</abbr>, <abbr title="Eli Upfal">EU</abbr>), pp. 681–690.</dd> <div class="pagevis" style="width:9px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-KakadeST.html">ICML-2008-KakadeST</a> <span class="tag"><a href="../tag/algorithm.html" title="algorithm">#algorithm</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/online.html" title="online">#online</a></span> <span class="tag"><a href="../tag/performance.html" title="performance">#performance</a></span> <span class="tag"><a href="../tag/predict.html" title="predict">#predict</a></span></dt><dd>Efficient bandit algorithms for online multiclass prediction (<abbr title="Sham M. Kakade">SMK</abbr>, <abbr title="Shai Shalev-Shwartz">SSS</abbr>, <abbr title="Ambuj Tewari">AT</abbr>), pp. 440–447.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2008-RadlinskiKJ.html">ICML-2008-RadlinskiKJ</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/ranking.html" title="ranking">#ranking</a></span></dt><dd>Learning diverse rankings with multi-armed bandits (<abbr title="Filip Radlinski">FR</abbr>, <abbr title="Robert Kleinberg">RK</abbr>, <abbr title="Thorsten Joachims">TJ</abbr>), pp. 784–791.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2007-PandeyCA.html">ICML-2007-PandeyCA</a> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Multi-armed bandit problems with dependent arms (<abbr title="Sandeep Pandey">SP</abbr>, <abbr title="Deepayan Chakrabarti">DC</abbr>, <abbr title="Deepak Agarwal">DA</abbr>), pp. 721–728.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-2006-StrehlMLH.html">ICML-2006-StrehlMLH</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Experience-efficient learning in associative bandit problems (<abbr title="Alexander L. Strehl">ALS</abbr>, <abbr title="Chris Mesterharm">CM</abbr>, <abbr title="Michael L. Littman">MLL</abbr>, <abbr title="Haym Hirsh">HH</abbr>), pp. 889–896.</dd> <div class="pagevis" style="width:7px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1998-Cesa-BianchiF.html">ICML-1998-Cesa-BianchiF</a> <span class="tag"><a href="../tag/bound.html" title="bound">#bound</a></span> <span class="tag"><a href="../tag/finite.html" title="finite">#finite</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Finite-Time Regret Bounds for the Multiarmed Bandit Problem (<abbr title="Nicolò Cesa-Bianchi">NCB</abbr>, <abbr title="Paul Fischer">PF</abbr>), pp. 100–108.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-Duff.html">ICML-1995-Duff</a> <span class="tag"><a href="../tag/problem.html" title="problem">#problem</a></span></dt><dd>Q-Learning for Bandit Problems (<abbr title="Michael O. Duff">MOD</abbr>), pp. 209–217.</dd> <div class="pagevis" style="width:8px"></div>
<dt><img src="../stuff/icml.png" alt="ICML"/><a href="../ICML-1995-SalganicoffU.html">ICML-1995-SalganicoffU</a> <span class="tag"><a href="../tag/learning.html" title="learning">#learning</a></span> <span class="tag"><a href="../tag/multi.html" title="multi">#multi</a></span> <span class="tag"><a href="../tag/using.html" title="using">#using</a></span></dt><dd>Active Exploration and Learning in real-Valued Spaces using Multi-Armed Bandit Allocation Indices (<abbr title="Marcos Salganicoff">MS</abbr>, <abbr title="Lyle H. Ungar">LHU</abbr>), pp. 480–487.</dd> <div class="pagevis" style="width:7px"></div></dl>
</div>
<hr style="clear:both"/>
<div class="last">
	<em>
		<a href="http://bibtex.github.io">Bibliography of Software Language Engineering in Generated Hypertext</a>
		(<a href="http://github.com/slebok/bibsleigh">BibSLEIGH</a>) is
		created and maintained by <a href="http://grammarware.github.io/">Dr. Vadim Zaytsev</a>.<br/>
		Hosted as a part of <a href="http://slebok.github.io/">SLEBOK</a> on <a href="http://www.github.com/">GitHub</a>.
	</em>
</div>
</body>
</html>